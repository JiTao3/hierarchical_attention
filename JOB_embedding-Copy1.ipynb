{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, Model, load_model, Model\n",
    "from tensorflow.keras import optimizers, activations\n",
    "from tensorflow.keras.layers import Dense, Flatten, LSTM, Bidirectional, SimpleRNN,Dropout\n",
    "from tensorflow.keras.losses import logcosh\n",
    "from tensorflow.metrics import mean_relative_error\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "from tensorflow.keras import regularizers\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def extract_time(line):\n",
    "    data = line.replace(\"->\",\"\").lstrip().split(\"  \")[-1].split(\" \")\n",
    "#     print(data)\n",
    "    start_cost = data[0].split(\"..\")[0].replace(\"(cost=\",\"\")\n",
    "#     print(start_cost)\n",
    "    end_cost = data[0].split(\"..\")[1]\n",
    "    rows = data[1].replace(\"rows=\",\"\")\n",
    "    width = data[2].replace(\"width=\",\"\").replace(\")\",\"\")\n",
    "    a_start_cost = data[4].split(\"..\")[0].replace(\"time=\",\"\")\n",
    "    a_end_cost = data[4].split(\"..\")[1]\n",
    "    a_rows = data[5].replace(\"rows=\",\"\") \n",
    "    return float(start_cost),float(end_cost),float(rows),float(width),float(a_start_cost),float(a_end_cost),float(a_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# file_name_column_min_max_vals = \"/home/slm/cardinality/learnedcardinalities/data/column_min_max_vals.csv\"\n",
    "# with open(file_name_column_min_max_vals, 'r') as f:\n",
    "#     data_raw = list(list(rec) for rec in csv.reader(f, delimiter=','))\n",
    "#     column_min_max_vals = {}\n",
    "#     for i, row in enumerate(data_raw):\n",
    "#         if i == 0:\n",
    "#             continue\n",
    "#         column_min_max_vals[row[0]] = [float(row[1]), float(row[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def normalize_data(val,column_name,column_min_max_vals):\n",
    "    min_val = column_min_max_vals[column_name][0]\n",
    "    max_val = column_min_max_vals[column_name][1]\n",
    "    val = float(val)\n",
    "    if(val>max_val):\n",
    "        val = max_val\n",
    "    elif(val<min_val):\n",
    "        val = min_val\n",
    "    val = float(val)\n",
    "    val_norm = (val - min_val) / (max_val - min_val)\n",
    "    return val_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def is_not_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return False\n",
    "    except ValueError:\n",
    "        pass\n",
    "    try:\n",
    "        import unicodedata\n",
    "        unicodedata.numeric(s)\n",
    "        return False\n",
    "    except (TypeError, ValueError):\n",
    "        pass\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_data_and_label(path):\n",
    "    plans = sorted(os.listdir(path))\n",
    "    sentences = []\n",
    "    rows = []\n",
    "    pg = []\n",
    "    d = {}\n",
    "    for file in sorted(plans):\n",
    "        with open(path+'/'+file,'r') as f:\n",
    "#             print(file)\n",
    "            plan = f.readlines()\n",
    "            for i in range(len(plan)-2):\n",
    "                if(\"Seq Scan\" in plan[i]):\n",
    "                    _start_cost,_end_cost,_rows,_width,_a_start_cost_,_a_end_cost,_a_rows = extract_time(plan[i])\n",
    "                    if(len(plan[i].strip().split(\"  \"))==2):\n",
    "                        _sentence = \" \".join(plan[i].strip().split(\"  \")[0].split(\" \")[:-1]) + \" \"\n",
    "                        table = plan[i].strip().split(\"  \")[0].split(\" \")[4]\n",
    "                    else:\n",
    "                        _sentence = \" \".join(plan[i].strip().split(\"  \")[1].split(\" \")[:-1]) + \" \"\n",
    "                        table = plan[i].strip().split(\"  \")[1].split(\" \")[4]\n",
    "                    if(\"actual\" not in plan[i+1] and \"Plan\" not in plan[i+1]):\n",
    "                        _sentence += plan[i+1].strip()\n",
    "#                         print(_sentence)\n",
    "                    else:\n",
    "                        _sentence += table\n",
    "                        _sentence += _sentence\n",
    "#                         _sentence = _sentence + ' full'\n",
    "#                         break\n",
    "    #                     pass\n",
    "#                         print(_sentence)\n",
    "                    _sentence = _sentence.replace(\": \",\" \").replace(\"(\",\"\").replace(\")\",\"\").replace(\"'\",\"\").replace(\"::bpchar\",\"\")\\\n",
    "                        .replace(\"[]\",\"\").replace(\",\",\" \").replace(\"\\\\\",\"\").replace(\"::numeric\",\"\").replace(\"  \",\" \")\\\n",
    "                        .replace(\"Seq Scan on \",\"\").strip()\n",
    "#                     print(_sentence)\n",
    "                    sentence = []\n",
    "                    ll = _sentence.split(\" \")\n",
    "                    for cnt in range(len(ll)):                 \n",
    "                        if is_not_number(ll[cnt]):\n",
    "                            sentence.append(ll[cnt])\n",
    "                        else:\n",
    "                            try:\n",
    "                                sentence.append(normalize_data(ll[cnt],table+'.'+str(ll[cnt-2]),column_min_max_vals))\n",
    "                            except:\n",
    "    #                             print(sentence)\n",
    "                                pass\n",
    "#                     print(sentence)\n",
    "#                     if(tuple(sentence) not in d):\n",
    "#                         d[tuple(sentence)] = 0\n",
    "                    sentences.append(tuple(sentence))\n",
    "                    rows.append(_a_rows)\n",
    "                    pg.append(_rows)\n",
    "    return sentences,rows,pg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'/home/jitao/hierarchical_attention/data/deep_cardinality'\n",
    "sentences,rows,pg = get_data_and_label(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [],
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "31\n['movie_info_idx', 'Filter', 'info_type_id', '>', 'title', 'kind_id', '=', 'movie_keyword', 'keyword_id', 'cast_info', 'person_id', 'AND', 'role_id', 'mkmovie_keyword', 'mk', 'ttitle', 't', '<', 'production_year', 'movie_info', 'mimovie_info', 'mi', 'movie_companies', 'mcmovie_companies', 'mc', 'cicast_info', 'ci', 'mi_idxmovie_info_idx', 'mi_idx', 'company_id', 'company_type_id']\n"
    }
   ],
   "source": [
    "vocabulary = []\n",
    "for sentence in sentences:\n",
    "    for word in sentence:\n",
    "        if(word not in vocabulary and is_not_number(word)):\n",
    "#             print(word)\n",
    "            vocabulary.append(word)\n",
    "print(len(vocabulary))\n",
    "vocab_size = len(vocabulary)\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "31\n",
    "['movie_info_idx', 'Filter', 'info_type_id', '>', 'title', 'kind_id', '=', 'production_year', 'movie_keyword', 'keyword_id', 'cast_info', 'person_id', 'AND', 'role_id', 'mkmovie_keyword', 'mk', 'ttitle', 't', '<', 'movie_info', 'mimovie_info', 'mi', 'movie_companies', 'mcmovie_companies', 'mc', 'cicast_info', 'ci', 'company_id', 'company_type_id', 'mi_idxmovie_info_idx', 'mi_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "_vocabulary = np.array(vocabulary)\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(_vocabulary)\n",
    "encoded = to_categorical(integer_encoded)\n",
    "vocab_dict = {}\n",
    "for v,e in zip(vocabulary,encoded):\n",
    "    vocab_dict[v] = np.reshape(np.array(e),(1,vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def prepare_data_and_label(sentences,rows):\n",
    "    data = []\n",
    "    label = []\n",
    "    for sentence,row in zip(sentences,rows):\n",
    "        _s = []\n",
    "        for word in sentence:\n",
    "            if(is_not_number(word)):\n",
    "                _tmp = np.column_stack((np.array([0]),vocab_dict[word]))\n",
    "                _tmp = np.reshape(_tmp,(vocab_size+1))\n",
    "                assert(len(_tmp)==vocab_size+1)\n",
    "                _s.append(_tmp)\n",
    "            else:\n",
    "#                 print(word)\n",
    "#                 _tmp = np.full((vocab_size+1),word)\n",
    "                _tmp = np.column_stack((np.array([float(word)]),np.zeros((1,vocab_size))))\n",
    "                _tmp = np.reshape(_tmp,(vocab_size+1))\n",
    "#                 print(_tmp)\n",
    "                assert(len(_tmp)==vocab_size+1)\n",
    "                _s.append(_tmp)\n",
    "        data.append(np.array(_s))\n",
    "        label.append(row)\n",
    "    return data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,label = prepare_data_and_label(sentences,rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_labels(labels, min_val=None, max_val=None):\n",
    "# log tranformation withour normalize\n",
    "    labels = np.array([np.log(float(l)) for l in labels]).astype(np.float32)\n",
    "    return labels,0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_norm, min_val, max_val = normalize_labels(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "7\n"
    }
   ],
   "source": [
    "max_len = 0\n",
    "for sentence in sentences:\n",
    "    if(len(sentence) > max_len):\n",
    "        max_len = len(sentence)\n",
    "print(max_len)\n",
    "padded_sentences = pad_sequences(data, maxlen=max_len, padding='pre',dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(176483, 7, 32)\n(176483,)\n"
    }
   ],
   "source": [
    "print(np.shape(padded_sentences))\n",
    "print(np.shape(label_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(35296, 7, 32) (141187, 7, 32)\n(35296,) (141187,)\n"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sentences, label_norm, test_size=0.8, random_state=40)\n",
    "pg_train,pg_test,_y_train,_y_test = train_test_split(pg,label_norm,test_size=0.2,random_state=40)\n",
    "print(np.shape(X_train),np.shape(X_test))\n",
    "print(np.shape(y_train),np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /home/jitao/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\nWARNING:tensorflow:From /home/jitao/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\nWARNING:tensorflow:From /home/jitao/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\nWARNING:tensorflow:From /home/jitao/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nbidirectional (Bidirectional (None, 7, 256)            41216     \n_________________________________________________________________\nbidirectional_1 (Bidirection (None, 7, 256)            98560     \n_________________________________________________________________\nflatten (Flatten)            (None, 1792)              0         \n_________________________________________________________________\ndropout (Dropout)            (None, 1792)              0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               229504    \n_________________________________________________________________\ndense_1 (Dense)              (None, 64)                8256      \n_________________________________________________________________\ndense_2 (Dense)              (None, 64)                4160      \n_________________________________________________________________\ndense_3 (Dense)              (None, 1)                 65        \n=================================================================\nTotal params: 381,761\nTrainable params: 381,761\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# model.add(Embedding(vocab_size, 5, input_length=max_len))\n",
    "# model.add(SimpleRNN(64, return_sequences=True,activation='relu',input_shape=(max_len,vocab_size+1)))\n",
    "# model.add(SimpleRNN(64,return_sequences=True,activation='relu'))\n",
    "model.add(Bidirectional(SimpleRNN(128, return_sequences=True,activation='relu'),input_shape=(max_len,vocab_size+1)))\n",
    "model.add(Bidirectional(SimpleRNN(128,return_sequences=True,activation='relu')))\n",
    "# model.add(Bidirectional(SimpleRNN(64,return_sequences=True,activation='relu')))\n",
    "# model.add(Bidirectional(SimpleRNN(64,return_sequences=True,activation='relu')))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(64,activation='relu'))#,kernel_regularizer=regularizers.l2(0.05)))\n",
    "# model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(64,activation='relu'))#,kernel_regularizer=regularizers.l2(0.05)))\n",
    "# model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "# model.compile(optimizer=optimizers.Adagrad(lr=0.01), loss=custom_loss(min_val,max_val), metrics=['mse','mae'])\n",
    "model.compile(optimizer=optimizers.Adagrad(lr=0.01,decay=0.0001), loss='mse', metrics=['mse','mae'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 141186 samples, validate on 35297 samples\nWARNING:tensorflow:From /home/jitao/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/adagrad.py:105: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\nEpoch 1/140\n141186/141186 [==============================] - 37s 264us/sample - loss: 5.7400 - mean_squared_error: 5.7400 - mean_absolute_error: 1.1310 - val_loss: 1.5508 - val_mean_squared_error: 1.5508 - val_mean_absolute_error: 0.8134\nEpoch 2/140\n141186/141186 [==============================] - 41s 290us/sample - loss: 1.6618 - mean_squared_error: 1.6618 - mean_absolute_error: 0.8492 - val_loss: 1.5169 - val_mean_squared_error: 1.5169 - val_mean_absolute_error: 0.7492\nEpoch 3/140\n141186/141186 [==============================] - 38s 270us/sample - loss: 1.6032 - mean_squared_error: 1.6032 - mean_absolute_error: 0.8205 - val_loss: 2.8890 - val_mean_squared_error: 2.8890 - val_mean_absolute_error: 1.2577\nEpoch 4/140\n141186/141186 [==============================] - 41s 288us/sample - loss: 1.5824 - mean_squared_error: 1.5824 - mean_absolute_error: 0.8076 - val_loss: 3.9047 - val_mean_squared_error: 3.9047 - val_mean_absolute_error: 1.5857\nEpoch 5/140\n141186/141186 [==============================] - 38s 270us/sample - loss: 1.5759 - mean_squared_error: 1.5759 - mean_absolute_error: 0.8013 - val_loss: 1.5154 - val_mean_squared_error: 1.5154 - val_mean_absolute_error: 0.7484\nEpoch 6/140\n141186/141186 [==============================] - 39s 275us/sample - loss: 1.5667 - mean_squared_error: 1.5667 - mean_absolute_error: 0.7949 - val_loss: 1.8409 - val_mean_squared_error: 1.8409 - val_mean_absolute_error: 1.0654\nEpoch 7/140\n141186/141186 [==============================] - 37s 263us/sample - loss: 1.5576 - mean_squared_error: 1.5576 - mean_absolute_error: 0.7905 - val_loss: 1.5527 - val_mean_squared_error: 1.5527 - val_mean_absolute_error: 0.7758\nEpoch 8/140\n141186/141186 [==============================] - 37s 260us/sample - loss: 1.5477 - mean_squared_error: 1.5477 - mean_absolute_error: 0.7862 - val_loss: 1.4623 - val_mean_squared_error: 1.4623 - val_mean_absolute_error: 0.6969\nEpoch 9/140\n141186/141186 [==============================] - 36s 257us/sample - loss: 1.5489 - mean_squared_error: 1.5489 - mean_absolute_error: 0.7833 - val_loss: 1.5437 - val_mean_squared_error: 1.5437 - val_mean_absolute_error: 0.7634\nEpoch 10/140\n141186/141186 [==============================] - 38s 267us/sample - loss: 1.5455 - mean_squared_error: 1.5455 - mean_absolute_error: 0.7834 - val_loss: 1.4638 - val_mean_squared_error: 1.4638 - val_mean_absolute_error: 0.7228\nEpoch 11/140\n141186/141186 [==============================] - 36s 255us/sample - loss: 1.5418 - mean_squared_error: 1.5418 - mean_absolute_error: 0.7796 - val_loss: 1.9327 - val_mean_squared_error: 1.9327 - val_mean_absolute_error: 0.8899\nEpoch 12/140\n141186/141186 [==============================] - 36s 254us/sample - loss: 1.5398 - mean_squared_error: 1.5398 - mean_absolute_error: 0.7794 - val_loss: 1.4711 - val_mean_squared_error: 1.4711 - val_mean_absolute_error: 0.6982\nEpoch 13/140\n141186/141186 [==============================] - 40s 282us/sample - loss: 1.5349 - mean_squared_error: 1.5349 - mean_absolute_error: 0.7760 - val_loss: 1.4662 - val_mean_squared_error: 1.4662 - val_mean_absolute_error: 0.7307\nEpoch 14/140\n141186/141186 [==============================] - 39s 275us/sample - loss: 1.5335 - mean_squared_error: 1.5335 - mean_absolute_error: 0.7759 - val_loss: 1.6961 - val_mean_squared_error: 1.6961 - val_mean_absolute_error: 0.8529\nEpoch 15/140\n141186/141186 [==============================] - 40s 282us/sample - loss: 1.5329 - mean_squared_error: 1.5329 - mean_absolute_error: 0.7748 - val_loss: 1.4938 - val_mean_squared_error: 1.4938 - val_mean_absolute_error: 0.7938\nEpoch 16/140\n141186/141186 [==============================] - 39s 275us/sample - loss: 1.5315 - mean_squared_error: 1.5315 - mean_absolute_error: 0.7734 - val_loss: 1.4760 - val_mean_squared_error: 1.4760 - val_mean_absolute_error: 0.7634\nEpoch 17/140\n141186/141186 [==============================] - 39s 275us/sample - loss: 1.5309 - mean_squared_error: 1.5309 - mean_absolute_error: 0.7730 - val_loss: 1.5180 - val_mean_squared_error: 1.5180 - val_mean_absolute_error: 0.8213\nEpoch 18/140\n141186/141186 [==============================] - 38s 272us/sample - loss: 1.5291 - mean_squared_error: 1.5291 - mean_absolute_error: 0.7722 - val_loss: 1.5598 - val_mean_squared_error: 1.5598 - val_mean_absolute_error: 0.8658\nEpoch 19/140\n141186/141186 [==============================] - 39s 273us/sample - loss: 1.5269 - mean_squared_error: 1.5269 - mean_absolute_error: 0.7707 - val_loss: 1.4873 - val_mean_squared_error: 1.4873 - val_mean_absolute_error: 0.7838\nEpoch 20/140\n141186/141186 [==============================] - 36s 257us/sample - loss: 1.5231 - mean_squared_error: 1.5231 - mean_absolute_error: 0.7693 - val_loss: 1.4569 - val_mean_squared_error: 1.4569 - val_mean_absolute_error: 0.6984\nEpoch 21/140\n141186/141186 [==============================] - 38s 272us/sample - loss: 1.5211 - mean_squared_error: 1.5211 - mean_absolute_error: 0.7681 - val_loss: 1.4900 - val_mean_squared_error: 1.4900 - val_mean_absolute_error: 0.7848\nEpoch 22/140\n141186/141186 [==============================] - 39s 275us/sample - loss: 1.5226 - mean_squared_error: 1.5226 - mean_absolute_error: 0.7685 - val_loss: 1.4634 - val_mean_squared_error: 1.4634 - val_mean_absolute_error: 0.6994\nEpoch 23/140\n141186/141186 [==============================] - 40s 286us/sample - loss: 1.5212 - mean_squared_error: 1.5212 - mean_absolute_error: 0.7675 - val_loss: 1.4826 - val_mean_squared_error: 1.4826 - val_mean_absolute_error: 0.7306\nEpoch 24/140\n141186/141186 [==============================] - 38s 271us/sample - loss: 1.5223 - mean_squared_error: 1.5223 - mean_absolute_error: 0.7673 - val_loss: 1.4666 - val_mean_squared_error: 1.4666 - val_mean_absolute_error: 0.7413\nEpoch 25/140\n141186/141186 [==============================] - 39s 277us/sample - loss: 1.5195 - mean_squared_error: 1.5195 - mean_absolute_error: 0.7668 - val_loss: 1.4737 - val_mean_squared_error: 1.4737 - val_mean_absolute_error: 0.7074\nEpoch 26/140\n141186/141186 [==============================] - 38s 270us/sample - loss: 1.5211 - mean_squared_error: 1.5211 - mean_absolute_error: 0.7661 - val_loss: 1.5472 - val_mean_squared_error: 1.5472 - val_mean_absolute_error: 0.7520\nEpoch 27/140\n141186/141186 [==============================] - 39s 273us/sample - loss: 1.5211 - mean_squared_error: 1.5211 - mean_absolute_error: 0.7654 - val_loss: 1.4690 - val_mean_squared_error: 1.4690 - val_mean_absolute_error: 0.7229\nEpoch 28/140\n141186/141186 [==============================] - 36s 259us/sample - loss: 1.5182 - mean_squared_error: 1.5182 - mean_absolute_error: 0.7649 - val_loss: 1.5305 - val_mean_squared_error: 1.5305 - val_mean_absolute_error: 0.8370\nEpoch 29/140\n141186/141186 [==============================] - 38s 269us/sample - loss: 1.5192 - mean_squared_error: 1.5191 - mean_absolute_error: 0.7656 - val_loss: 1.4960 - val_mean_squared_error: 1.4960 - val_mean_absolute_error: 0.7939\nEpoch 30/140\n141186/141186 [==============================] - 37s 260us/sample - loss: 1.5165 - mean_squared_error: 1.5165 - mean_absolute_error: 0.7644 - val_loss: 1.4673 - val_mean_squared_error: 1.4673 - val_mean_absolute_error: 0.7066\nEpoch 31/140\n141186/141186 [==============================] - 37s 259us/sample - loss: 1.5155 - mean_squared_error: 1.5155 - mean_absolute_error: 0.7639 - val_loss: 1.5367 - val_mean_squared_error: 1.5367 - val_mean_absolute_error: 0.7414\nEpoch 32/140\n141186/141186 [==============================] - 39s 276us/sample - loss: 1.5173 - mean_squared_error: 1.5173 - mean_absolute_error: 0.7639 - val_loss: 1.6504 - val_mean_squared_error: 1.6504 - val_mean_absolute_error: 0.9417\nEpoch 33/140\n141186/141186 [==============================] - 39s 277us/sample - loss: 1.5176 - mean_squared_error: 1.5176 - mean_absolute_error: 0.7641 - val_loss: 1.4570 - val_mean_squared_error: 1.4570 - val_mean_absolute_error: 0.6866\nEpoch 34/140\n141186/141186 [==============================] - 39s 273us/sample - loss: 1.5178 - mean_squared_error: 1.5178 - mean_absolute_error: 0.7635 - val_loss: 1.5535 - val_mean_squared_error: 1.5535 - val_mean_absolute_error: 0.8607\nEpoch 35/140\n141186/141186 [==============================] - 38s 272us/sample - loss: 1.5147 - mean_squared_error: 1.5147 - mean_absolute_error: 0.7618 - val_loss: 1.4728 - val_mean_squared_error: 1.4728 - val_mean_absolute_error: 0.7552\nEpoch 36/140\n141186/141186 [==============================] - 38s 269us/sample - loss: 1.5149 - mean_squared_error: 1.5149 - mean_absolute_error: 0.7623 - val_loss: 1.4584 - val_mean_squared_error: 1.4584 - val_mean_absolute_error: 0.7099\nEpoch 37/140\n141186/141186 [==============================] - 38s 269us/sample - loss: 1.5161 - mean_squared_error: 1.5161 - mean_absolute_error: 0.7625 - val_loss: 1.5867 - val_mean_squared_error: 1.5867 - val_mean_absolute_error: 0.8878\nEpoch 38/140\n141186/141186 [==============================] - 37s 263us/sample - loss: 1.5142 - mean_squared_error: 1.5142 - mean_absolute_error: 0.7624 - val_loss: 1.4677 - val_mean_squared_error: 1.4677 - val_mean_absolute_error: 0.7448\nEpoch 39/140\n141186/141186 [==============================] - 37s 263us/sample - loss: 1.5157 - mean_squared_error: 1.5157 - mean_absolute_error: 0.7624 - val_loss: 1.4938 - val_mean_squared_error: 1.4938 - val_mean_absolute_error: 0.7911\nEpoch 40/140\n141186/141186 [==============================] - 37s 265us/sample - loss: 1.5125 - mean_squared_error: 1.5125 - mean_absolute_error: 0.7617 - val_loss: 1.6300 - val_mean_squared_error: 1.6300 - val_mean_absolute_error: 0.9185\nEpoch 41/140\n141186/141186 [==============================] - 36s 256us/sample - loss: 1.5156 - mean_squared_error: 1.5156 - mean_absolute_error: 0.7621 - val_loss: 1.4702 - val_mean_squared_error: 1.4702 - val_mean_absolute_error: 0.7097\nEpoch 42/140\n141186/141186 [==============================] - 38s 273us/sample - loss: 1.5164 - mean_squared_error: 1.5164 - mean_absolute_error: 0.7620 - val_loss: 1.4738 - val_mean_squared_error: 1.4738 - val_mean_absolute_error: 0.7583\nEpoch 43/140\n141186/141186 [==============================] - 38s 269us/sample - loss: 1.5134 - mean_squared_error: 1.5134 - mean_absolute_error: 0.7610 - val_loss: 1.4870 - val_mean_squared_error: 1.4870 - val_mean_absolute_error: 0.7836\nEpoch 44/140\n141186/141186 [==============================] - 39s 277us/sample - loss: 1.5139 - mean_squared_error: 1.5139 - mean_absolute_error: 0.7610 - val_loss: 1.7195 - val_mean_squared_error: 1.7195 - val_mean_absolute_error: 0.9909\nEpoch 45/140\n141186/141186 [==============================] - 37s 262us/sample - loss: 1.5085 - mean_squared_error: 1.5085 - mean_absolute_error: 0.7604 - val_loss: 1.5203 - val_mean_squared_error: 1.5203 - val_mean_absolute_error: 0.8245\nEpoch 46/140\n141186/141186 [==============================] - 39s 276us/sample - loss: 1.5140 - mean_squared_error: 1.5140 - mean_absolute_error: 0.7618 - val_loss: 1.5284 - val_mean_squared_error: 1.5284 - val_mean_absolute_error: 0.8341\nEpoch 47/140\n141186/141186 [==============================] - 37s 264us/sample - loss: 1.5112 - mean_squared_error: 1.5112 - mean_absolute_error: 0.7603 - val_loss: 1.4548 - val_mean_squared_error: 1.4548 - val_mean_absolute_error: 0.6987\nEpoch 48/140\n141186/141186 [==============================] - 38s 268us/sample - loss: 1.5127 - mean_squared_error: 1.5127 - mean_absolute_error: 0.7597 - val_loss: 1.4639 - val_mean_squared_error: 1.4639 - val_mean_absolute_error: 0.7354\nEpoch 49/140\n141186/141186 [==============================] - 36s 254us/sample - loss: 1.5096 - mean_squared_error: 1.5096 - mean_absolute_error: 0.7594 - val_loss: 1.4550 - val_mean_squared_error: 1.4550 - val_mean_absolute_error: 0.7007\nEpoch 50/140\n141186/141186 [==============================] - 37s 265us/sample - loss: 1.5116 - mean_squared_error: 1.5116 - mean_absolute_error: 0.7602 - val_loss: 1.4559 - val_mean_squared_error: 1.4559 - val_mean_absolute_error: 0.6943\nEpoch 51/140\n141186/141186 [==============================] - 36s 257us/sample - loss: 1.5087 - mean_squared_error: 1.5087 - mean_absolute_error: 0.7578 - val_loss: 1.4613 - val_mean_squared_error: 1.4613 - val_mean_absolute_error: 0.7267\nEpoch 52/140\n141186/141186 [==============================] - 36s 255us/sample - loss: 1.5097 - mean_squared_error: 1.5097 - mean_absolute_error: 0.7594 - val_loss: 1.4857 - val_mean_squared_error: 1.4857 - val_mean_absolute_error: 0.7779\nEpoch 53/140\n141186/141186 [==============================] - 38s 269us/sample - loss: 1.5100 - mean_squared_error: 1.5100 - mean_absolute_error: 0.7595 - val_loss: 1.4676 - val_mean_squared_error: 1.4676 - val_mean_absolute_error: 0.7425\nEpoch 54/140\n141186/141186 [==============================] - 39s 276us/sample - loss: 1.5091 - mean_squared_error: 1.5091 - mean_absolute_error: 0.7586 - val_loss: 1.4566 - val_mean_squared_error: 1.4566 - val_mean_absolute_error: 0.7057\nEpoch 55/140\n141186/141186 [==============================] - 40s 285us/sample - loss: 1.5112 - mean_squared_error: 1.5112 - mean_absolute_error: 0.7587 - val_loss: 1.4557 - val_mean_squared_error: 1.4557 - val_mean_absolute_error: 0.7007\nEpoch 56/140\n141186/141186 [==============================] - 38s 269us/sample - loss: 1.5091 - mean_squared_error: 1.5091 - mean_absolute_error: 0.7582 - val_loss: 1.4691 - val_mean_squared_error: 1.4691 - val_mean_absolute_error: 0.7473\nEpoch 57/140\n141186/141186 [==============================] - 39s 278us/sample - loss: 1.5122 - mean_squared_error: 1.5122 - mean_absolute_error: 0.7593 - val_loss: 1.4713 - val_mean_squared_error: 1.4713 - val_mean_absolute_error: 0.7509\nEpoch 58/140\n141186/141186 [==============================] - 37s 266us/sample - loss: 1.5123 - mean_squared_error: 1.5123 - mean_absolute_error: 0.7590 - val_loss: 1.4776 - val_mean_squared_error: 1.4776 - val_mean_absolute_error: 0.7648\nEpoch 59/140\n141186/141186 [==============================] - 39s 275us/sample - loss: 1.5085 - mean_squared_error: 1.5085 - mean_absolute_error: 0.7576 - val_loss: 1.4662 - val_mean_squared_error: 1.4662 - val_mean_absolute_error: 0.7385\nEpoch 60/140\n141186/141186 [==============================] - 36s 257us/sample - loss: 1.5085 - mean_squared_error: 1.5085 - mean_absolute_error: 0.7571 - val_loss: 1.5480 - val_mean_squared_error: 1.5480 - val_mean_absolute_error: 0.8553\nEpoch 61/140\n141186/141186 [==============================] - 38s 272us/sample - loss: 1.5099 - mean_squared_error: 1.5099 - mean_absolute_error: 0.7584 - val_loss: 1.4582 - val_mean_squared_error: 1.4582 - val_mean_absolute_error: 0.6852\nEpoch 62/140\n141186/141186 [==============================] - 36s 257us/sample - loss: 1.5102 - mean_squared_error: 1.5102 - mean_absolute_error: 0.7581 - val_loss: 1.4647 - val_mean_squared_error: 1.4647 - val_mean_absolute_error: 0.7369\nEpoch 63/140\n141186/141186 [==============================] - 39s 275us/sample - loss: 1.5084 - mean_squared_error: 1.5084 - mean_absolute_error: 0.7572 - val_loss: 1.4640 - val_mean_squared_error: 1.4640 - val_mean_absolute_error: 0.7363\nEpoch 64/140\n141186/141186 [==============================] - 38s 272us/sample - loss: 1.5077 - mean_squared_error: 1.5077 - mean_absolute_error: 0.7574 - val_loss: 1.5345 - val_mean_squared_error: 1.5345 - val_mean_absolute_error: 0.8405\nEpoch 65/140\n141186/141186 [==============================] - 39s 274us/sample - loss: 1.5074 - mean_squared_error: 1.5074 - mean_absolute_error: 0.7568 - val_loss: 1.4606 - val_mean_squared_error: 1.4606 - val_mean_absolute_error: 0.7232\nEpoch 66/140\n141186/141186 [==============================] - 38s 272us/sample - loss: 1.5060 - mean_squared_error: 1.5060 - mean_absolute_error: 0.7568 - val_loss: 1.4601 - val_mean_squared_error: 1.4601 - val_mean_absolute_error: 0.7209\nEpoch 67/140\n141186/141186 [==============================] - 38s 270us/sample - loss: 1.5085 - mean_squared_error: 1.5085 - mean_absolute_error: 0.7580 - val_loss: 1.4608 - val_mean_squared_error: 1.4608 - val_mean_absolute_error: 0.7203\nEpoch 68/140\n141186/141186 [==============================] - 38s 272us/sample - loss: 1.5069 - mean_squared_error: 1.5069 - mean_absolute_error: 0.7582 - val_loss: 1.4610 - val_mean_squared_error: 1.4610 - val_mean_absolute_error: 0.7227\nEpoch 69/140\n141186/141186 [==============================] - 36s 256us/sample - loss: 1.5069 - mean_squared_error: 1.5069 - mean_absolute_error: 0.7572 - val_loss: 1.4808 - val_mean_squared_error: 1.4808 - val_mean_absolute_error: 0.7732\nEpoch 70/140\n141186/141186 [==============================] - 38s 270us/sample - loss: 1.5078 - mean_squared_error: 1.5078 - mean_absolute_error: 0.7569 - val_loss: 1.4575 - val_mean_squared_error: 1.4575 - val_mean_absolute_error: 0.7132\nEpoch 71/140\n141186/141186 [==============================] - 36s 254us/sample - loss: 1.5049 - mean_squared_error: 1.5049 - mean_absolute_error: 0.7560 - val_loss: 1.4786 - val_mean_squared_error: 1.4786 - val_mean_absolute_error: 0.7658\nEpoch 72/140\n141186/141186 [==============================] - 38s 270us/sample - loss: 1.5082 - mean_squared_error: 1.5082 - mean_absolute_error: 0.7575 - val_loss: 1.4682 - val_mean_squared_error: 1.4682 - val_mean_absolute_error: 0.7448\nEpoch 73/140\n141186/141186 [==============================] - 35s 249us/sample - loss: 1.5048 - mean_squared_error: 1.5048 - mean_absolute_error: 0.7563 - val_loss: 1.4714 - val_mean_squared_error: 1.4714 - val_mean_absolute_error: 0.7518\nEpoch 74/140\n141186/141186 [==============================] - 40s 284us/sample - loss: 1.5098 - mean_squared_error: 1.5098 - mean_absolute_error: 0.7577 - val_loss: 1.4930 - val_mean_squared_error: 1.4930 - val_mean_absolute_error: 0.7916\nEpoch 75/140\n141186/141186 [==============================] - 38s 268us/sample - loss: 1.5081 - mean_squared_error: 1.5081 - mean_absolute_error: 0.7575 - val_loss: 1.4751 - val_mean_squared_error: 1.4751 - val_mean_absolute_error: 0.7598\nEpoch 76/140\n141186/141186 [==============================] - 39s 279us/sample - loss: 1.5079 - mean_squared_error: 1.5079 - mean_absolute_error: 0.7565 - val_loss: 1.4742 - val_mean_squared_error: 1.4742 - val_mean_absolute_error: 0.7592\nEpoch 77/140\n141186/141186 [==============================] - 38s 267us/sample - loss: 1.5059 - mean_squared_error: 1.5059 - mean_absolute_error: 0.7559 - val_loss: 1.4748 - val_mean_squared_error: 1.4748 - val_mean_absolute_error: 0.7585\nEpoch 78/140\n141186/141186 [==============================] - 39s 273us/sample - loss: 1.5075 - mean_squared_error: 1.5075 - mean_absolute_error: 0.7563 - val_loss: 1.4635 - val_mean_squared_error: 1.4635 - val_mean_absolute_error: 0.7335\nEpoch 79/140\n141186/141186 [==============================] - 37s 265us/sample - loss: 1.5079 - mean_squared_error: 1.5079 - mean_absolute_error: 0.7566 - val_loss: 1.4554 - val_mean_squared_error: 1.4554 - val_mean_absolute_error: 0.6916\nEpoch 80/140\n141186/141186 [==============================] - 37s 265us/sample - loss: 1.5088 - mean_squared_error: 1.5088 - mean_absolute_error: 0.7558 - val_loss: 1.4701 - val_mean_squared_error: 1.4701 - val_mean_absolute_error: 0.7493\nEpoch 81/140\n141186/141186 [==============================] - 37s 261us/sample - loss: 1.5037 - mean_squared_error: 1.5037 - mean_absolute_error: 0.7556 - val_loss: 1.4722 - val_mean_squared_error: 1.4722 - val_mean_absolute_error: 0.7538\nEpoch 82/140\n141186/141186 [==============================] - 37s 261us/sample - loss: 1.5045 - mean_squared_error: 1.5045 - mean_absolute_error: 0.7559 - val_loss: 1.4622 - val_mean_squared_error: 1.4622 - val_mean_absolute_error: 0.7294\nEpoch 83/140\n141186/141186 [==============================] - 37s 263us/sample - loss: 1.5045 - mean_squared_error: 1.5045 - mean_absolute_error: 0.7553 - val_loss: 1.4585 - val_mean_squared_error: 1.4585 - val_mean_absolute_error: 0.7140\nEpoch 84/140\n141186/141186 [==============================] - 36s 254us/sample - loss: 1.5057 - mean_squared_error: 1.5057 - mean_absolute_error: 0.7560 - val_loss: 1.4607 - val_mean_squared_error: 1.4607 - val_mean_absolute_error: 0.7248\nEpoch 85/140\n141186/141186 [==============================] - 39s 279us/sample - loss: 1.5058 - mean_squared_error: 1.5058 - mean_absolute_error: 0.7562 - val_loss: 1.4737 - val_mean_squared_error: 1.4737 - val_mean_absolute_error: 0.7581\nEpoch 86/140\n141186/141186 [==============================] - 37s 263us/sample - loss: 1.5040 - mean_squared_error: 1.5040 - mean_absolute_error: 0.7554 - val_loss: 1.4684 - val_mean_squared_error: 1.4684 - val_mean_absolute_error: 0.7457\nEpoch 87/140\n141186/141186 [==============================] - 39s 277us/sample - loss: 1.5056 - mean_squared_error: 1.5056 - mean_absolute_error: 0.7559 - val_loss: 1.4805 - val_mean_squared_error: 1.4805 - val_mean_absolute_error: 0.7709\nEpoch 88/140\n141186/141186 [==============================] - 36s 257us/sample - loss: 1.5041 - mean_squared_error: 1.5041 - mean_absolute_error: 0.7555 - val_loss: 1.5273 - val_mean_squared_error: 1.5273 - val_mean_absolute_error: 0.8323\nEpoch 89/140\n141186/141186 [==============================] - 39s 274us/sample - loss: 1.5056 - mean_squared_error: 1.5056 - mean_absolute_error: 0.7554 - val_loss: 1.4597 - val_mean_squared_error: 1.4597 - val_mean_absolute_error: 0.7187\nEpoch 90/140\n141186/141186 [==============================] - 37s 259us/sample - loss: 1.5038 - mean_squared_error: 1.5038 - mean_absolute_error: 0.7544 - val_loss: 1.4654 - val_mean_squared_error: 1.4654 - val_mean_absolute_error: 0.7379\nEpoch 91/140\n141186/141186 [==============================] - 37s 264us/sample - loss: 1.5080 - mean_squared_error: 1.5080 - mean_absolute_error: 0.7555 - val_loss: 1.4702 - val_mean_squared_error: 1.4702 - val_mean_absolute_error: 0.7490\nEpoch 92/140\n141186/141186 [==============================] - 36s 254us/sample - loss: 1.5065 - mean_squared_error: 1.5065 - mean_absolute_error: 0.7559 - val_loss: 1.4612 - val_mean_squared_error: 1.4612 - val_mean_absolute_error: 0.7247\nEpoch 93/140\n141186/141186 [==============================] - 37s 264us/sample - loss: 1.5046 - mean_squared_error: 1.5046 - mean_absolute_error: 0.7548 - val_loss: 1.4611 - val_mean_squared_error: 1.4611 - val_mean_absolute_error: 0.7257\nEpoch 94/140\n141186/141186 [==============================] - 36s 257us/sample - loss: 1.5021 - mean_squared_error: 1.5021 - mean_absolute_error: 0.7539 - val_loss: 1.4710 - val_mean_squared_error: 1.4710 - val_mean_absolute_error: 0.7531\nEpoch 95/140\n141186/141186 [==============================] - 36s 255us/sample - loss: 1.5058 - mean_squared_error: 1.5058 - mean_absolute_error: 0.7554 - val_loss: 1.4671 - val_mean_squared_error: 1.4671 - val_mean_absolute_error: 0.7442\nEpoch 96/140\n141186/141186 [==============================] - 36s 253us/sample - loss: 1.5029 - mean_squared_error: 1.5029 - mean_absolute_error: 0.7538 - val_loss: 1.4918 - val_mean_squared_error: 1.4918 - val_mean_absolute_error: 0.7890\nEpoch 97/140\n141186/141186 [==============================] - 39s 277us/sample - loss: 1.5021 - mean_squared_error: 1.5021 - mean_absolute_error: 0.7549 - val_loss: 1.5179 - val_mean_squared_error: 1.5179 - val_mean_absolute_error: 0.8230\nEpoch 98/140\n141186/141186 [==============================] - 39s 279us/sample - loss: 1.5036 - mean_squared_error: 1.5036 - mean_absolute_error: 0.7546 - val_loss: 1.4694 - val_mean_squared_error: 1.4694 - val_mean_absolute_error: 0.7482\nEpoch 99/140\n141186/141186 [==============================] - 38s 270us/sample - loss: 1.5029 - mean_squared_error: 1.5028 - mean_absolute_error: 0.7543 - val_loss: 1.4667 - val_mean_squared_error: 1.4667 - val_mean_absolute_error: 0.7427\nEpoch 100/140\n141186/141186 [==============================] - 39s 280us/sample - loss: 1.5051 - mean_squared_error: 1.5051 - mean_absolute_error: 0.7550 - val_loss: 1.4780 - val_mean_squared_error: 1.4780 - val_mean_absolute_error: 0.7639\nEpoch 101/140\n141186/141186 [==============================] - 38s 268us/sample - loss: 1.5041 - mean_squared_error: 1.5041 - mean_absolute_error: 0.7548 - val_loss: 1.4654 - val_mean_squared_error: 1.4654 - val_mean_absolute_error: 0.7363\nEpoch 102/140\n141186/141186 [==============================] - 39s 277us/sample - loss: 1.5039 - mean_squared_error: 1.5039 - mean_absolute_error: 0.7550 - val_loss: 1.4719 - val_mean_squared_error: 1.4719 - val_mean_absolute_error: 0.7535\nEpoch 103/140\n141186/141186 [==============================] - 36s 256us/sample - loss: 1.5050 - mean_squared_error: 1.5050 - mean_absolute_error: 0.7546 - val_loss: 1.4926 - val_mean_squared_error: 1.4926 - val_mean_absolute_error: 0.7904\nEpoch 104/140\n141186/141186 [==============================] - 39s 277us/sample - loss: 1.5029 - mean_squared_error: 1.5029 - mean_absolute_error: 0.7545 - val_loss: 1.4703 - val_mean_squared_error: 1.4703 - val_mean_absolute_error: 0.7484\nEpoch 105/140\n141186/141186 [==============================] - 36s 253us/sample - loss: 1.5041 - mean_squared_error: 1.5041 - mean_absolute_error: 0.7550 - val_loss: 1.5239 - val_mean_squared_error: 1.5239 - val_mean_absolute_error: 0.8306\nEpoch 106/140\n141186/141186 [==============================] - 39s 278us/sample - loss: 1.5018 - mean_squared_error: 1.5018 - mean_absolute_error: 0.7538 - val_loss: 1.4672 - val_mean_squared_error: 1.4672 - val_mean_absolute_error: 0.7425\nEpoch 107/140\n141186/141186 [==============================] - 39s 277us/sample - loss: 1.5025 - mean_squared_error: 1.5025 - mean_absolute_error: 0.7539 - val_loss: 1.4706 - val_mean_squared_error: 1.4706 - val_mean_absolute_error: 0.7505\nEpoch 108/140\n141186/141186 [==============================] - 39s 278us/sample - loss: 1.5029 - mean_squared_error: 1.5029 - mean_absolute_error: 0.7532 - val_loss: 1.4831 - val_mean_squared_error: 1.4831 - val_mean_absolute_error: 0.7748\nEpoch 109/140\n141186/141186 [==============================] - 39s 274us/sample - loss: 1.5036 - mean_squared_error: 1.5036 - mean_absolute_error: 0.7545 - val_loss: 1.4742 - val_mean_squared_error: 1.4742 - val_mean_absolute_error: 0.7575\nEpoch 110/140\n141186/141186 [==============================] - 39s 274us/sample - loss: 1.5040 - mean_squared_error: 1.5040 - mean_absolute_error: 0.7544 - val_loss: 1.4784 - val_mean_squared_error: 1.4784 - val_mean_absolute_error: 0.7662\nEpoch 111/140\n141186/141186 [==============================] - 38s 268us/sample - loss: 1.5046 - mean_squared_error: 1.5046 - mean_absolute_error: 0.7544 - val_loss: 1.4901 - val_mean_squared_error: 1.4901 - val_mean_absolute_error: 0.7861\nEpoch 112/140\n141186/141186 [==============================] - 37s 259us/sample - loss: 1.5040 - mean_squared_error: 1.5040 - mean_absolute_error: 0.7552 - val_loss: 1.4621 - val_mean_squared_error: 1.4621 - val_mean_absolute_error: 0.7297\nEpoch 113/140\n141186/141186 [==============================] - 38s 266us/sample - loss: 1.5042 - mean_squared_error: 1.5042 - mean_absolute_error: 0.7538 - val_loss: 1.4578 - val_mean_squared_error: 1.4578 - val_mean_absolute_error: 0.7132\nEpoch 114/140\n141186/141186 [==============================] - 37s 262us/sample - loss: 1.5038 - mean_squared_error: 1.5038 - mean_absolute_error: 0.7529 - val_loss: 1.4641 - val_mean_squared_error: 1.4641 - val_mean_absolute_error: 0.7354\nEpoch 115/140\n141186/141186 [==============================] - 37s 264us/sample - loss: 1.5050 - mean_squared_error: 1.5050 - mean_absolute_error: 0.7536 - val_loss: 1.4647 - val_mean_squared_error: 1.4647 - val_mean_absolute_error: 0.7363\nEpoch 116/140\n141186/141186 [==============================] - 38s 271us/sample - loss: 1.5047 - mean_squared_error: 1.5047 - mean_absolute_error: 0.7539 - val_loss: 1.4951 - val_mean_squared_error: 1.4951 - val_mean_absolute_error: 0.7943\nEpoch 117/140\n141186/141186 [==============================] - 39s 277us/sample - loss: 1.5036 - mean_squared_error: 1.5036 - mean_absolute_error: 0.7534 - val_loss: 1.4719 - val_mean_squared_error: 1.4719 - val_mean_absolute_error: 0.7540\nEpoch 118/140\n141186/141186 [==============================] - 37s 264us/sample - loss: 1.5057 - mean_squared_error: 1.5057 - mean_absolute_error: 0.7542 - val_loss: 1.4757 - val_mean_squared_error: 1.4757 - val_mean_absolute_error: 0.7603\nEpoch 119/140\n141186/141186 [==============================] - 39s 278us/sample - loss: 1.5028 - mean_squared_error: 1.5028 - mean_absolute_error: 0.7537 - val_loss: 1.4774 - val_mean_squared_error: 1.4774 - val_mean_absolute_error: 0.7641\nEpoch 120/140\n141186/141186 [==============================] - 37s 262us/sample - loss: 1.5034 - mean_squared_error: 1.5034 - mean_absolute_error: 0.7537 - val_loss: 1.4742 - val_mean_squared_error: 1.4742 - val_mean_absolute_error: 0.7585\nEpoch 121/140\n141186/141186 [==============================] - 38s 272us/sample - loss: 1.5039 - mean_squared_error: 1.5039 - mean_absolute_error: 0.7536 - val_loss: 1.4721 - val_mean_squared_error: 1.4721 - val_mean_absolute_error: 0.7540\nEpoch 122/140\n141186/141186 [==============================] - 36s 256us/sample - loss: 1.5032 - mean_squared_error: 1.5032 - mean_absolute_error: 0.7533 - val_loss: 1.4680 - val_mean_squared_error: 1.4680 - val_mean_absolute_error: 0.7448\nEpoch 123/140\n141186/141186 [==============================] - 36s 254us/sample - loss: 1.5037 - mean_squared_error: 1.5037 - mean_absolute_error: 0.7534 - val_loss: 1.4670 - val_mean_squared_error: 1.4670 - val_mean_absolute_error: 0.7428\nEpoch 124/140\n141186/141186 [==============================] - 37s 264us/sample - loss: 1.5030 - mean_squared_error: 1.5030 - mean_absolute_error: 0.7524 - val_loss: 1.4842 - val_mean_squared_error: 1.4842 - val_mean_absolute_error: 0.7758\nEpoch 125/140\n141186/141186 [==============================] - 37s 261us/sample - loss: 1.5034 - mean_squared_error: 1.5034 - mean_absolute_error: 0.7536 - val_loss: 1.4892 - val_mean_squared_error: 1.4892 - val_mean_absolute_error: 0.7841\nEpoch 126/140\n141186/141186 [==============================] - 35s 251us/sample - loss: 1.5052 - mean_squared_error: 1.5052 - mean_absolute_error: 0.7543 - val_loss: 1.4771 - val_mean_squared_error: 1.4771 - val_mean_absolute_error: 0.7633\nEpoch 127/140\n141186/141186 [==============================] - 38s 268us/sample - loss: 1.5029 - mean_squared_error: 1.5029 - mean_absolute_error: 0.7536 - val_loss: 1.4925 - val_mean_squared_error: 1.4925 - val_mean_absolute_error: 0.7888\nEpoch 128/140\n141186/141186 [==============================] - 39s 273us/sample - loss: 1.5042 - mean_squared_error: 1.5042 - mean_absolute_error: 0.7540 - val_loss: 1.4702 - val_mean_squared_error: 1.4702 - val_mean_absolute_error: 0.7501\nEpoch 129/140\n141186/141186 [==============================] - 37s 263us/sample - loss: 1.5040 - mean_squared_error: 1.5040 - mean_absolute_error: 0.7537 - val_loss: 1.4728 - val_mean_squared_error: 1.4728 - val_mean_absolute_error: 0.7553\nEpoch 130/140\n141186/141186 [==============================] - 39s 277us/sample - loss: 1.5038 - mean_squared_error: 1.5038 - mean_absolute_error: 0.7532 - val_loss: 1.4689 - val_mean_squared_error: 1.4689 - val_mean_absolute_error: 0.7475\nEpoch 131/140\n141186/141186 [==============================] - 37s 262us/sample - loss: 1.5017 - mean_squared_error: 1.5017 - mean_absolute_error: 0.7524 - val_loss: 1.4687 - val_mean_squared_error: 1.4687 - val_mean_absolute_error: 0.7465\nEpoch 132/140\n141186/141186 [==============================] - 39s 277us/sample - loss: 1.5027 - mean_squared_error: 1.5027 - mean_absolute_error: 0.7534 - val_loss: 1.4729 - val_mean_squared_error: 1.4729 - val_mean_absolute_error: 0.7554\nEpoch 133/140\n141186/141186 [==============================] - 35s 250us/sample - loss: 1.5025 - mean_squared_error: 1.5025 - mean_absolute_error: 0.7531 - val_loss: 1.4839 - val_mean_squared_error: 1.4839 - val_mean_absolute_error: 0.7770\nEpoch 134/140\n141186/141186 [==============================] - 37s 259us/sample - loss: 1.5038 - mean_squared_error: 1.5038 - mean_absolute_error: 0.7533 - val_loss: 1.4607 - val_mean_squared_error: 1.4607 - val_mean_absolute_error: 0.7262\nEpoch 135/140\n141186/141186 [==============================] - 36s 256us/sample - loss: 1.5043 - mean_squared_error: 1.5043 - mean_absolute_error: 0.7534 - val_loss: 1.4711 - val_mean_squared_error: 1.4711 - val_mean_absolute_error: 0.7527\nEpoch 136/140\n141186/141186 [==============================] - 37s 263us/sample - loss: 1.4998 - mean_squared_error: 1.4998 - mean_absolute_error: 0.7521 - val_loss: 1.4669 - val_mean_squared_error: 1.4669 - val_mean_absolute_error: 0.7418\nEpoch 137/140\n141186/141186 [==============================] - 36s 254us/sample - loss: 1.5021 - mean_squared_error: 1.5021 - mean_absolute_error: 0.7529 - val_loss: 1.4762 - val_mean_squared_error: 1.4762 - val_mean_absolute_error: 0.7638\nEpoch 138/140\n141186/141186 [==============================] - 36s 252us/sample - loss: 1.5017 - mean_squared_error: 1.5017 - mean_absolute_error: 0.7525 - val_loss: 1.4857 - val_mean_squared_error: 1.4857 - val_mean_absolute_error: 0.7799\nEpoch 139/140\n141186/141186 [==============================] - 39s 277us/sample - loss: 1.4976 - mean_squared_error: 1.4976 - mean_absolute_error: 0.7518 - val_loss: 1.4739 - val_mean_squared_error: 1.4739 - val_mean_absolute_error: 0.7573\nEpoch 140/140\n141186/141186 [==============================] - 39s 274us/sample - loss: 1.5015 - mean_squared_error: 1.5015 - mean_absolute_error: 0.7523 - val_loss: 1.4693 - val_mean_squared_error: 1.4693 - val_mean_absolute_error: 0.7481\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7fec5c054450>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# model.fit(X_train,y_train,validation_split=0.2,epochs=100, batch_size=8,shuffle=True)\n",
    "model.fit(padded_sentences,label_norm,validation_split=0.2,epochs=140, batch_size=128,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('./final/embedding_model_bak.h5') \n",
    "# model = tf.keras.models.load_model('./final/embedding_model_bak.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_path = r'/data1/slm/datasets/JOB/synthetic/'\n",
    "# # test_path = r'/data/slm/datasets/JOB/job-light/'\n",
    "# # test_path = r'/data1/slm/datasets/JOB/cardinality/'\n",
    "# test_sentences,test_rows,test_pg = get_data_and_label(test_path)\n",
    "# test_data,test_label = prepare_data_and_label(test_sentences,test_rows)\n",
    "# print(np.shape(test_data),np.shape(test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # label_norm, min_val, max_val = normalize_labels(label)\n",
    "# max_len = 0\n",
    "# for test_sentence in test_sentences:\n",
    "#     if(len(test_sentence) > max_len):\n",
    "#         max_len = len(test_sentence)\n",
    "# print(max_len)\n",
    "# test_padded_sentences = pad_sequences(test_data, maxlen=max_len, padding='pre',dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.shape(test_padded_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = model.predict(test_padded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _pg = plt.scatter(test_label,test_pg,c='b')\n",
    "# my = plt.scatter(test_label,np.exp(pred),c='r')\n",
    "# plt.legend([_pg, my], ['pg', 'my'], loc='lower right', scatterpoints=1)\n",
    "# _max = max(test_label)\n",
    "# plt.plot([0,_max],[0,_max],c=\"y\")\n",
    "# plt.plot([0,_max],[0,2*_max],c=\"y\")\n",
    "# plt.plot([0,_max],[0,0.5*_max],c=\"y\")\n",
    "# plt.savefig(\"./results/test_embedding_result.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# result = np.exp(pred.flatten())/test_label\n",
    "# pg_result = np.array(test_pg)/np.array(test_label)\n",
    "# ax = plt.subplot(1, 2, 1)\n",
    "# ax.boxplot(np.log(np.array(result)),showfliers=False)\n",
    "# # ax.set_yticks(np.arange(0, 10))\n",
    "# # ax.set_yticklabels(math.e**np.arange(-10, 10))\n",
    "# ax.set_title('my q-error')\n",
    "# ax2 = plt.subplot(1,2,2)\n",
    "# ax2.boxplot(np.log(np.array(pg_result)),showfliers=False)\n",
    "# # ax2.set_yticklabels(math.e**np.arange(-10, 10))\n",
    "# ax2.set_title('pg q-error')\n",
    "# # plt.savefig(\"test_box-2.png\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# def print_qerror(preds_norm, labels_unnorm):\n",
    "#     qerror = []\n",
    "#     preds_unnorm = np.exp(preds_norm)-1\n",
    "# #     labels_unnorm = np.exp(labels_norm)-1\n",
    "#     for i in range(len(preds_unnorm)):\n",
    "#         if preds_unnorm[i] > float(labels_unnorm[i]):\n",
    "#             qerror.append(preds_unnorm[i] / float(labels_unnorm[i]))\n",
    "#         else:\n",
    "#             qerror.append(float(labels_unnorm[i]) / float(preds_unnorm[i]))\n",
    "\n",
    "#     print(\"Median: {}\".format(np.median(qerror)))\n",
    "#     print(\"90th percentile: {}\".format(np.percentile(qerror, 90)))\n",
    "#     print(\"95th percentile: {}\".format(np.percentile(qerror, 95)))\n",
    "#     print(\"99th percentile: {}\".format(np.percentile(qerror, 99)))\n",
    "#     print(\"Max: {}\".format(np.max(qerror)))\n",
    "#     print(\"Mean: {}\".format(np.mean(qerror)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_qerror(pred,test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bak better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.layers[6].output)\n",
    "# intermediate_output = intermediate_layer_model.predict(test_padded_sentences)\n",
    "\n",
    "intermediate_output = intermediate_layer_model.predict(padded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scan_label = []\n",
    "# scan_label.append(['table','detail'])\n",
    "# for sentence in sentences:\n",
    "#     tmp = []\n",
    "# #     print(sentence)\n",
    "#     table = sentence[0]\n",
    "#     tmp.append(table)\n",
    "#     if(len(sentence)>2):\n",
    "#         tmp.append(' '.join(str(each) for each in sentence[2:]))\n",
    "#     else:\n",
    "#         tmp.append(table)\n",
    "#     scan_label.append(tmp)\n",
    "# #     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(\"vectors.csv\", intermediate_output, delimiter=\"\\t\")\n",
    "# np.savetxt(\"labels.csv\",scan_label,fmt='%s',delimiter = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(176483, 64)\n"
    }
   ],
   "source": [
    "print(np.shape(intermediate_output))\n",
    "# print(np.shape(scan_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"model_parameter/featuer_deep_cardinality.npy\",intermediate_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "176483"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "intermediate_output[:3]\n",
    "len(intermediate_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 592.875222,
   "position": {
    "height": "40px",
    "left": "901.667px",
    "right": "20px",
    "top": "87px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}