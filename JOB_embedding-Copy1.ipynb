{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, Model, load_model, Model\n",
    "from tensorflow.keras import optimizers, activations\n",
    "from tensorflow.keras.layers import Dense, Flatten, LSTM, Bidirectional, SimpleRNN,Dropout\n",
    "from tensorflow.keras.losses import logcosh\n",
    "from tensorflow.metrics import mean_relative_error\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "from tensorflow.keras import regularizers\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def extract_time(line):\n",
    "    data = line.replace(\"->\",\"\").lstrip().split(\"  \")[-1].split(\" \")\n",
    "#     print(data)\n",
    "    start_cost = data[0].split(\"..\")[0].replace(\"(cost=\",\"\")\n",
    "#     print(start_cost)\n",
    "    end_cost = data[0].split(\"..\")[1]\n",
    "    rows = data[1].replace(\"rows=\",\"\")\n",
    "    width = data[2].replace(\"width=\",\"\").replace(\")\",\"\")\n",
    "    a_start_cost = data[4].split(\"..\")[0].replace(\"time=\",\"\")\n",
    "    a_end_cost = data[4].split(\"..\")[1]\n",
    "    a_rows = data[5].replace(\"rows=\",\"\") \n",
    "    return float(start_cost),float(end_cost),float(rows),float(width),float(a_start_cost),float(a_end_cost),float(a_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# file_name_column_min_max_vals = \"/home/slm/cardinality/learnedcardinalities/data/column_min_max_vals.csv\"\n",
    "# with open(file_name_column_min_max_vals, 'r') as f:\n",
    "#     data_raw = list(list(rec) for rec in csv.reader(f, delimiter=','))\n",
    "#     column_min_max_vals = {}\n",
    "#     for i, row in enumerate(data_raw):\n",
    "#         if i == 0:\n",
    "#             continue\n",
    "#         column_min_max_vals[row[0]] = [float(row[1]), float(row[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def normalize_data(val,column_name,column_min_max_vals):\n",
    "    min_val = column_min_max_vals[column_name][0]\n",
    "    max_val = column_min_max_vals[column_name][1]\n",
    "    val = float(val)\n",
    "    if(val>max_val):\n",
    "        val = max_val\n",
    "    elif(val<min_val):\n",
    "        val = min_val\n",
    "    val = float(val)\n",
    "    val_norm = (val - min_val) / (max_val - min_val)\n",
    "    return val_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def is_not_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return False\n",
    "    except ValueError:\n",
    "        pass\n",
    "    try:\n",
    "        import unicodedata\n",
    "        unicodedata.numeric(s)\n",
    "        return False\n",
    "    except (TypeError, ValueError):\n",
    "        pass\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_data_and_label(path):\n",
    "    plans = sorted(os.listdir(path))\n",
    "    sentences = []\n",
    "    rows = []\n",
    "    pg = []\n",
    "    d = {}\n",
    "    for file in sorted(plans):\n",
    "        with open(path+'/'+file,'r') as f:\n",
    "#             print(file)\n",
    "            plan = f.readlines()\n",
    "            for i in range(len(plan)-2):\n",
    "                if(\"Seq Scan\" in plan[i]):\n",
    "                    _start_cost,_end_cost,_rows,_width,_a_start_cost_,_a_end_cost,_a_rows = extract_time(plan[i])\n",
    "                    if(len(plan[i].strip().split(\"  \"))==2):\n",
    "                        _sentence = \" \".join(plan[i].strip().split(\"  \")[0].split(\" \")[:-1]) + \" \"\n",
    "                        table = plan[i].strip().split(\"  \")[0].split(\" \")[4]\n",
    "                    else:\n",
    "                        _sentence = \" \".join(plan[i].strip().split(\"  \")[1].split(\" \")[:-1]) + \" \"\n",
    "                        table = plan[i].strip().split(\"  \")[1].split(\" \")[4]\n",
    "                    if(\"actual\" not in plan[i+1] and \"Plan\" not in plan[i+1]):\n",
    "                        _sentence += plan[i+1].strip()\n",
    "#                         print(_sentence)\n",
    "                    else:\n",
    "                        _sentence += table\n",
    "                        _sentence += _sentence\n",
    "#                         _sentence = _sentence + ' full'\n",
    "#                         break\n",
    "    #                     pass\n",
    "#                         print(_sentence)\n",
    "                    _sentence = _sentence.replace(\": \",\" \").replace(\"(\",\"\").replace(\")\",\"\").replace(\"'\",\"\").replace(\"::bpchar\",\"\")\\\n",
    "                        .replace(\"[]\",\"\").replace(\",\",\" \").replace(\"\\\\\",\"\").replace(\"::numeric\",\"\").replace(\"  \",\" \")\\\n",
    "                        .replace(\"Seq Scan on \",\"\").strip()\n",
    "#                     print(_sentence)\n",
    "                    sentence = []\n",
    "                    ll = _sentence.split(\" \")\n",
    "                    for cnt in range(len(ll)):                 \n",
    "                        if is_not_number(ll[cnt]):\n",
    "                            sentence.append(ll[cnt])\n",
    "                        else:\n",
    "                            try:\n",
    "                                sentence.append(normalize_data(ll[cnt],table+'.'+str(ll[cnt-2]),column_min_max_vals))\n",
    "                            except:\n",
    "    #                             print(sentence)\n",
    "                                pass\n",
    "#                     print(sentence)\n",
    "#                     if(tuple(sentence) not in d):\n",
    "#                         d[tuple(sentence)] = 0\n",
    "                    sentences.append(tuple(sentence))\n",
    "                    rows.append(_a_rows)\n",
    "                    pg.append(_rows)\n",
    "    return sentences,rows,pg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'/home/jitao/hierarchical_attention/data/cardinality'\n",
    "sentences,rows,pg = get_data_and_label(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [],
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "31\n['movie_info', 'Filter', 'info_type_id', '>', 'title', 'kind_id', '<', 'AND', 'production_year', '=', 'movie_keyword', 'keyword_id', 'movie_companies', 'company_id', 'mcmovie_companies', 'mc', 'cast_info', 'person_id', 'role_id', 'mkmovie_keyword', 'mk', 'movie_info_idx', 'mi_idxmovie_info_idx', 'mi_idx', 'ttitle', 't', 'company_type_id', 'mimovie_info', 'mi', 'cicast_info', 'ci']\n"
    }
   ],
   "source": [
    "vocabulary = []\n",
    "for sentence in sentences:\n",
    "    for word in sentence:\n",
    "        if(word not in vocabulary and is_not_number(word)):\n",
    "#             print(word)\n",
    "            vocabulary.append(word)\n",
    "print(len(vocabulary))\n",
    "vocab_size = len(vocabulary)\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "31\n",
    "['movie_info_idx', 'Filter', 'info_type_id', '>', 'title', 'kind_id', '=', 'production_year', 'movie_keyword', 'keyword_id', 'cast_info', 'person_id', 'AND', 'role_id', 'mkmovie_keyword', 'mk', 'ttitle', 't', '<', 'movie_info', 'mimovie_info', 'mi', 'movie_companies', 'mcmovie_companies', 'mc', 'cicast_info', 'ci', 'company_id', 'company_type_id', 'mi_idxmovie_info_idx', 'mi_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "_vocabulary = np.array(vocabulary)\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(_vocabulary)\n",
    "encoded = to_categorical(integer_encoded)\n",
    "vocab_dict = {}\n",
    "for v,e in zip(vocabulary,encoded):\n",
    "    vocab_dict[v] = np.reshape(np.array(e),(1,vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def prepare_data_and_label(sentences,rows):\n",
    "    data = []\n",
    "    label = []\n",
    "    for sentence,row in zip(sentences,rows):\n",
    "        _s = []\n",
    "        for word in sentence:\n",
    "            if(is_not_number(word)):\n",
    "                _tmp = np.column_stack((np.array([0]),vocab_dict[word]))\n",
    "                _tmp = np.reshape(_tmp,(vocab_size+1))\n",
    "                assert(len(_tmp)==vocab_size+1)\n",
    "                _s.append(_tmp)\n",
    "            else:\n",
    "#                 print(word)\n",
    "#                 _tmp = np.full((vocab_size+1),word)\n",
    "                _tmp = np.column_stack((np.array([float(word)]),np.zeros((1,vocab_size))))\n",
    "                _tmp = np.reshape(_tmp,(vocab_size+1))\n",
    "#                 print(_tmp)\n",
    "                assert(len(_tmp)==vocab_size+1)\n",
    "                _s.append(_tmp)\n",
    "        data.append(np.array(_s))\n",
    "        label.append(row)\n",
    "    return data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,label = prepare_data_and_label(sentences,rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_labels(labels, min_val=None, max_val=None):\n",
    "# log tranformation withour normalize\n",
    "    labels = np.array([np.log(float(l)) for l in labels]).astype(np.float32)\n",
    "    return labels,0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_norm, min_val, max_val = normalize_labels(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "7\n"
    }
   ],
   "source": [
    "max_len = 0\n",
    "for sentence in sentences:\n",
    "    if(len(sentence) > max_len):\n",
    "        max_len = len(sentence)\n",
    "print(max_len)\n",
    "padded_sentences = pad_sequences(data, maxlen=max_len, padding='pre',dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(8858, 7, 32)\n(8858,)\n"
    }
   ],
   "source": [
    "print(np.shape(padded_sentences))\n",
    "print(np.shape(label_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1771, 7, 32) (7087, 7, 32)\n(1771,) (7087,)\n"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(padded_sentences, label_norm, test_size=0.8, random_state=40)\n",
    "pg_train,pg_test,_y_train,_y_test = train_test_split(pg,label_norm,test_size=0.2,random_state=40)\n",
    "print(np.shape(X_train),np.shape(X_test))\n",
    "print(np.shape(y_train),np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:From /home/jitao/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\nWARNING:tensorflow:From /home/jitao/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\nWARNING:tensorflow:From /home/jitao/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\nWARNING:tensorflow:From /home/jitao/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nbidirectional (Bidirectional (None, 7, 256)            41216     \n_________________________________________________________________\nbidirectional_1 (Bidirection (None, 7, 256)            98560     \n_________________________________________________________________\nflatten (Flatten)            (None, 1792)              0         \n_________________________________________________________________\ndropout (Dropout)            (None, 1792)              0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               229504    \n_________________________________________________________________\ndense_1 (Dense)              (None, 64)                8256      \n_________________________________________________________________\ndense_2 (Dense)              (None, 64)                4160      \n_________________________________________________________________\ndense_3 (Dense)              (None, 1)                 65        \n=================================================================\nTotal params: 381,761\nTrainable params: 381,761\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# model.add(Embedding(vocab_size, 5, input_length=max_len))\n",
    "# model.add(SimpleRNN(64, return_sequences=True,activation='relu',input_shape=(max_len,vocab_size+1)))\n",
    "# model.add(SimpleRNN(64,return_sequences=True,activation='relu'))\n",
    "model.add(Bidirectional(SimpleRNN(128, return_sequences=True,activation='relu'),input_shape=(max_len,vocab_size+1)))\n",
    "model.add(Bidirectional(SimpleRNN(128,return_sequences=True,activation='relu')))\n",
    "# model.add(Bidirectional(SimpleRNN(64,return_sequences=True,activation='relu')))\n",
    "# model.add(Bidirectional(SimpleRNN(64,return_sequences=True,activation='relu')))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(64,activation='relu'))#,kernel_regularizer=regularizers.l2(0.05)))\n",
    "# model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(64,activation='relu'))#,kernel_regularizer=regularizers.l2(0.05)))\n",
    "# model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "# model.compile(optimizer=optimizers.Adagrad(lr=0.01), loss=custom_loss(min_val,max_val), metrics=['mse','mae'])\n",
    "model.compile(optimizer=optimizers.Adagrad(lr=0.01,decay=0.0001), loss='mse', metrics=['mse','mae'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 7086 samples, validate on 1772 samples\nWARNING:tensorflow:From /home/jitao/anaconda3/envs/pytorch/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/adagrad.py:105: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nCall initializer instance with the dtype argument instead of passing it to the constructor\nEpoch 1/140\n7086/7086 [==============================] - 3s 425us/sample - loss: 65.7026 - mean_squared_error: 65.7026 - mean_absolute_error: 4.3072 - val_loss: 4.6900 - val_mean_squared_error: 4.6900 - val_mean_absolute_error: 1.2984\nEpoch 2/140\n7086/7086 [==============================] - 2s 244us/sample - loss: 4.3362 - mean_squared_error: 4.3362 - mean_absolute_error: 1.4354 - val_loss: 3.5312 - val_mean_squared_error: 3.5312 - val_mean_absolute_error: 1.1854\nEpoch 3/140\n7086/7086 [==============================] - 2s 231us/sample - loss: 3.6474 - mean_squared_error: 3.6474 - mean_absolute_error: 1.3515 - val_loss: 2.7996 - val_mean_squared_error: 2.7996 - val_mean_absolute_error: 0.9977\nEpoch 4/140\n7086/7086 [==============================] - 2s 234us/sample - loss: 2.8586 - mean_squared_error: 2.8586 - mean_absolute_error: 1.1794 - val_loss: 3.4990 - val_mean_squared_error: 3.4990 - val_mean_absolute_error: 1.5574\nEpoch 5/140\n7086/7086 [==============================] - 2s 243us/sample - loss: 2.3965 - mean_squared_error: 2.3965 - mean_absolute_error: 1.0913 - val_loss: 2.0522 - val_mean_squared_error: 2.0522 - val_mean_absolute_error: 0.9761\nEpoch 6/140\n7086/7086 [==============================] - 2s 247us/sample - loss: 2.2124 - mean_squared_error: 2.2124 - mean_absolute_error: 1.0428 - val_loss: 1.9658 - val_mean_squared_error: 1.9658 - val_mean_absolute_error: 0.9013\nEpoch 7/140\n7086/7086 [==============================] - 2s 241us/sample - loss: 2.0059 - mean_squared_error: 2.0059 - mean_absolute_error: 0.9716 - val_loss: 1.9254 - val_mean_squared_error: 1.9254 - val_mean_absolute_error: 1.0074\nEpoch 8/140\n7086/7086 [==============================] - 2s 235us/sample - loss: 1.9580 - mean_squared_error: 1.9580 - mean_absolute_error: 0.9665 - val_loss: 1.6905 - val_mean_squared_error: 1.6905 - val_mean_absolute_error: 0.7927\nEpoch 9/140\n7086/7086 [==============================] - 2s 242us/sample - loss: 1.8472 - mean_squared_error: 1.8472 - mean_absolute_error: 0.9238 - val_loss: 1.7728 - val_mean_squared_error: 1.7728 - val_mean_absolute_error: 0.8812\nEpoch 10/140\n7086/7086 [==============================] - 2s 271us/sample - loss: 1.8888 - mean_squared_error: 1.8888 - mean_absolute_error: 0.9505 - val_loss: 1.6798 - val_mean_squared_error: 1.6798 - val_mean_absolute_error: 0.8515\nEpoch 11/140\n7086/7086 [==============================] - 2s 259us/sample - loss: 1.7718 - mean_squared_error: 1.7718 - mean_absolute_error: 0.9031 - val_loss: 2.3331 - val_mean_squared_error: 2.3331 - val_mean_absolute_error: 1.2314\nEpoch 12/140\n7086/7086 [==============================] - 2s 247us/sample - loss: 1.7969 - mean_squared_error: 1.7969 - mean_absolute_error: 0.9111 - val_loss: 1.7188 - val_mean_squared_error: 1.7188 - val_mean_absolute_error: 0.7943\nEpoch 13/140\n7086/7086 [==============================] - 2s 224us/sample - loss: 1.7413 - mean_squared_error: 1.7413 - mean_absolute_error: 0.8930 - val_loss: 1.8136 - val_mean_squared_error: 1.8136 - val_mean_absolute_error: 0.9521\nEpoch 14/140\n7086/7086 [==============================] - 2s 222us/sample - loss: 1.7036 - mean_squared_error: 1.7036 - mean_absolute_error: 0.8799 - val_loss: 1.6644 - val_mean_squared_error: 1.6644 - val_mean_absolute_error: 0.8017\nEpoch 15/140\n7086/7086 [==============================] - 2s 215us/sample - loss: 1.7427 - mean_squared_error: 1.7427 - mean_absolute_error: 0.8905 - val_loss: 1.6465 - val_mean_squared_error: 1.6465 - val_mean_absolute_error: 0.8222\nEpoch 16/140\n7086/7086 [==============================] - 2s 222us/sample - loss: 1.7581 - mean_squared_error: 1.7581 - mean_absolute_error: 0.8972 - val_loss: 1.6484 - val_mean_squared_error: 1.6484 - val_mean_absolute_error: 0.8236\nEpoch 17/140\n7086/7086 [==============================] - 2s 217us/sample - loss: 1.7459 - mean_squared_error: 1.7459 - mean_absolute_error: 0.8939 - val_loss: 1.7243 - val_mean_squared_error: 1.7243 - val_mean_absolute_error: 0.8200\nEpoch 18/140\n7086/7086 [==============================] - 2s 217us/sample - loss: 1.7233 - mean_squared_error: 1.7233 - mean_absolute_error: 0.8794 - val_loss: 1.6824 - val_mean_squared_error: 1.6824 - val_mean_absolute_error: 0.7947\nEpoch 19/140\n7086/7086 [==============================] - 2s 216us/sample - loss: 1.7373 - mean_squared_error: 1.7373 - mean_absolute_error: 0.8867 - val_loss: 1.6356 - val_mean_squared_error: 1.6356 - val_mean_absolute_error: 0.7653\nEpoch 20/140\n7086/7086 [==============================] - 2s 215us/sample - loss: 1.6960 - mean_squared_error: 1.6960 - mean_absolute_error: 0.8705 - val_loss: 1.7225 - val_mean_squared_error: 1.7225 - val_mean_absolute_error: 0.8019\nEpoch 21/140\n7086/7086 [==============================] - 2s 221us/sample - loss: 1.7080 - mean_squared_error: 1.7080 - mean_absolute_error: 0.8664 - val_loss: 1.6427 - val_mean_squared_error: 1.6427 - val_mean_absolute_error: 0.8145\nEpoch 22/140\n7086/7086 [==============================] - 2s 217us/sample - loss: 1.7249 - mean_squared_error: 1.7249 - mean_absolute_error: 0.8814 - val_loss: 1.8382 - val_mean_squared_error: 1.8382 - val_mean_absolute_error: 1.0002\nEpoch 23/140\n7086/7086 [==============================] - 2s 217us/sample - loss: 1.7046 - mean_squared_error: 1.7046 - mean_absolute_error: 0.8691 - val_loss: 2.4368 - val_mean_squared_error: 2.4368 - val_mean_absolute_error: 1.2957\nEpoch 24/140\n7086/7086 [==============================] - 2s 217us/sample - loss: 1.7230 - mean_squared_error: 1.7230 - mean_absolute_error: 0.8804 - val_loss: 1.6350 - val_mean_squared_error: 1.6350 - val_mean_absolute_error: 0.7983\nEpoch 25/140\n7086/7086 [==============================] - 2s 215us/sample - loss: 1.6763 - mean_squared_error: 1.6763 - mean_absolute_error: 0.8625 - val_loss: 1.6354 - val_mean_squared_error: 1.6354 - val_mean_absolute_error: 0.7720\nEpoch 26/140\n7086/7086 [==============================] - 2s 219us/sample - loss: 1.6841 - mean_squared_error: 1.6841 - mean_absolute_error: 0.8663 - val_loss: 1.7252 - val_mean_squared_error: 1.7252 - val_mean_absolute_error: 0.9098\nEpoch 27/140\n7086/7086 [==============================] - 2s 219us/sample - loss: 1.6801 - mean_squared_error: 1.6801 - mean_absolute_error: 0.8621 - val_loss: 1.7320 - val_mean_squared_error: 1.7320 - val_mean_absolute_error: 0.9125\nEpoch 28/140\n7086/7086 [==============================] - 2s 216us/sample - loss: 1.6973 - mean_squared_error: 1.6973 - mean_absolute_error: 0.8680 - val_loss: 1.6067 - val_mean_squared_error: 1.6067 - val_mean_absolute_error: 0.7471\nEpoch 29/140\n7086/7086 [==============================] - 2s 218us/sample - loss: 1.6973 - mean_squared_error: 1.6973 - mean_absolute_error: 0.8716 - val_loss: 1.6420 - val_mean_squared_error: 1.6420 - val_mean_absolute_error: 0.7952\nEpoch 30/140\n7086/7086 [==============================] - 2s 220us/sample - loss: 1.6542 - mean_squared_error: 1.6542 - mean_absolute_error: 0.8502 - val_loss: 1.6151 - val_mean_squared_error: 1.6151 - val_mean_absolute_error: 0.7526\nEpoch 31/140\n7086/7086 [==============================] - 2s 214us/sample - loss: 1.6699 - mean_squared_error: 1.6699 - mean_absolute_error: 0.8512 - val_loss: 1.6157 - val_mean_squared_error: 1.6157 - val_mean_absolute_error: 0.7662\nEpoch 32/140\n7086/7086 [==============================] - 2s 223us/sample - loss: 1.6641 - mean_squared_error: 1.6641 - mean_absolute_error: 0.8516 - val_loss: 1.6214 - val_mean_squared_error: 1.6214 - val_mean_absolute_error: 0.7977\nEpoch 33/140\n7086/7086 [==============================] - 2s 218us/sample - loss: 1.6478 - mean_squared_error: 1.6478 - mean_absolute_error: 0.8459 - val_loss: 1.6603 - val_mean_squared_error: 1.6603 - val_mean_absolute_error: 0.8404\nEpoch 34/140\n7086/7086 [==============================] - 2s 220us/sample - loss: 1.6436 - mean_squared_error: 1.6436 - mean_absolute_error: 0.8477 - val_loss: 1.6143 - val_mean_squared_error: 1.6143 - val_mean_absolute_error: 0.7408\nEpoch 35/140\n7086/7086 [==============================] - 2s 215us/sample - loss: 1.6827 - mean_squared_error: 1.6827 - mean_absolute_error: 0.8581 - val_loss: 1.6381 - val_mean_squared_error: 1.6381 - val_mean_absolute_error: 0.7620\nEpoch 36/140\n7086/7086 [==============================] - 2s 216us/sample - loss: 1.6712 - mean_squared_error: 1.6712 - mean_absolute_error: 0.8566 - val_loss: 1.6699 - val_mean_squared_error: 1.6699 - val_mean_absolute_error: 0.8549\nEpoch 37/140\n7086/7086 [==============================] - 2s 217us/sample - loss: 1.6481 - mean_squared_error: 1.6481 - mean_absolute_error: 0.8469 - val_loss: 1.6164 - val_mean_squared_error: 1.6164 - val_mean_absolute_error: 0.7865\nEpoch 38/140\n7086/7086 [==============================] - 2s 223us/sample - loss: 1.6615 - mean_squared_error: 1.6615 - mean_absolute_error: 0.8515 - val_loss: 1.6112 - val_mean_squared_error: 1.6112 - val_mean_absolute_error: 0.7695\nEpoch 39/140\n7086/7086 [==============================] - 2s 285us/sample - loss: 1.6448 - mean_squared_error: 1.6448 - mean_absolute_error: 0.8409 - val_loss: 1.6168 - val_mean_squared_error: 1.6168 - val_mean_absolute_error: 0.7695\nEpoch 40/140\n7086/7086 [==============================] - 2s 281us/sample - loss: 1.6474 - mean_squared_error: 1.6474 - mean_absolute_error: 0.8436 - val_loss: 1.7439 - val_mean_squared_error: 1.7439 - val_mean_absolute_error: 0.8083\nEpoch 41/140\n7086/7086 [==============================] - 2s 244us/sample - loss: 1.6704 - mean_squared_error: 1.6704 - mean_absolute_error: 0.8543 - val_loss: 1.6447 - val_mean_squared_error: 1.6447 - val_mean_absolute_error: 0.7568\nEpoch 42/140\n7086/7086 [==============================] - 2s 239us/sample - loss: 1.6654 - mean_squared_error: 1.6654 - mean_absolute_error: 0.8463 - val_loss: 1.6246 - val_mean_squared_error: 1.6246 - val_mean_absolute_error: 0.7564\nEpoch 43/140\n7086/7086 [==============================] - 2s 228us/sample - loss: 1.6435 - mean_squared_error: 1.6435 - mean_absolute_error: 0.8434 - val_loss: 1.6199 - val_mean_squared_error: 1.6199 - val_mean_absolute_error: 0.7841\nEpoch 44/140\n7086/7086 [==============================] - 2s 230us/sample - loss: 1.6674 - mean_squared_error: 1.6674 - mean_absolute_error: 0.8501 - val_loss: 1.6329 - val_mean_squared_error: 1.6329 - val_mean_absolute_error: 0.7761\nEpoch 45/140\n7086/7086 [==============================] - 2s 230us/sample - loss: 1.6362 - mean_squared_error: 1.6362 - mean_absolute_error: 0.8363 - val_loss: 1.6369 - val_mean_squared_error: 1.6369 - val_mean_absolute_error: 0.8161\nEpoch 46/140\n7086/7086 [==============================] - 2s 235us/sample - loss: 1.6332 - mean_squared_error: 1.6332 - mean_absolute_error: 0.8359 - val_loss: 1.6829 - val_mean_squared_error: 1.6829 - val_mean_absolute_error: 0.8705\nEpoch 47/140\n7086/7086 [==============================] - 2s 234us/sample - loss: 1.6218 - mean_squared_error: 1.6218 - mean_absolute_error: 0.8332 - val_loss: 1.6028 - val_mean_squared_error: 1.6028 - val_mean_absolute_error: 0.7442\nEpoch 48/140\n7086/7086 [==============================] - 2s 232us/sample - loss: 1.6569 - mean_squared_error: 1.6569 - mean_absolute_error: 0.8471 - val_loss: 1.6210 - val_mean_squared_error: 1.6210 - val_mean_absolute_error: 0.7903\nEpoch 49/140\n7086/7086 [==============================] - 2s 278us/sample - loss: 1.6230 - mean_squared_error: 1.6230 - mean_absolute_error: 0.8354 - val_loss: 1.7948 - val_mean_squared_error: 1.7948 - val_mean_absolute_error: 0.8455\nEpoch 50/140\n7086/7086 [==============================] - 2s 252us/sample - loss: 1.6184 - mean_squared_error: 1.6184 - mean_absolute_error: 0.8356 - val_loss: 1.6125 - val_mean_squared_error: 1.6125 - val_mean_absolute_error: 0.7643\nEpoch 51/140\n7086/7086 [==============================] - 2s 226us/sample - loss: 1.6395 - mean_squared_error: 1.6395 - mean_absolute_error: 0.8407 - val_loss: 1.6063 - val_mean_squared_error: 1.6063 - val_mean_absolute_error: 0.7375\nEpoch 52/140\n7086/7086 [==============================] - 2s 218us/sample - loss: 1.6170 - mean_squared_error: 1.6170 - mean_absolute_error: 0.8305 - val_loss: 1.6096 - val_mean_squared_error: 1.6096 - val_mean_absolute_error: 0.7469\nEpoch 53/140\n7086/7086 [==============================] - 2s 217us/sample - loss: 1.6289 - mean_squared_error: 1.6289 - mean_absolute_error: 0.8374 - val_loss: 1.6040 - val_mean_squared_error: 1.6040 - val_mean_absolute_error: 0.7451\nEpoch 54/140\n7086/7086 [==============================] - 2s 216us/sample - loss: 1.6415 - mean_squared_error: 1.6415 - mean_absolute_error: 0.8344 - val_loss: 1.6568 - val_mean_squared_error: 1.6568 - val_mean_absolute_error: 0.8398\nEpoch 55/140\n7086/7086 [==============================] - 2s 214us/sample - loss: 1.6115 - mean_squared_error: 1.6115 - mean_absolute_error: 0.8270 - val_loss: 1.7218 - val_mean_squared_error: 1.7218 - val_mean_absolute_error: 0.9136\nEpoch 56/140\n7086/7086 [==============================] - 2s 217us/sample - loss: 1.6214 - mean_squared_error: 1.6214 - mean_absolute_error: 0.8297 - val_loss: 1.6638 - val_mean_squared_error: 1.6638 - val_mean_absolute_error: 0.8518\nEpoch 57/140\n7086/7086 [==============================] - 2s 213us/sample - loss: 1.6402 - mean_squared_error: 1.6402 - mean_absolute_error: 0.8389 - val_loss: 1.6415 - val_mean_squared_error: 1.6415 - val_mean_absolute_error: 0.8160\nEpoch 58/140\n7086/7086 [==============================] - 2s 212us/sample - loss: 1.6179 - mean_squared_error: 1.6179 - mean_absolute_error: 0.8310 - val_loss: 1.6081 - val_mean_squared_error: 1.6081 - val_mean_absolute_error: 0.7405\nEpoch 59/140\n7086/7086 [==============================] - 2s 214us/sample - loss: 1.6230 - mean_squared_error: 1.6230 - mean_absolute_error: 0.8282 - val_loss: 1.7901 - val_mean_squared_error: 1.7901 - val_mean_absolute_error: 0.9580\nEpoch 60/140\n7086/7086 [==============================] - 1s 211us/sample - loss: 1.6191 - mean_squared_error: 1.6191 - mean_absolute_error: 0.8332 - val_loss: 1.6589 - val_mean_squared_error: 1.6589 - val_mean_absolute_error: 0.8432\nEpoch 61/140\n7086/7086 [==============================] - 2s 216us/sample - loss: 1.6154 - mean_squared_error: 1.6154 - mean_absolute_error: 0.8302 - val_loss: 1.6273 - val_mean_squared_error: 1.6273 - val_mean_absolute_error: 0.7778\nEpoch 62/140\n7086/7086 [==============================] - 2s 219us/sample - loss: 1.5984 - mean_squared_error: 1.5984 - mean_absolute_error: 0.8210 - val_loss: 1.6052 - val_mean_squared_error: 1.6052 - val_mean_absolute_error: 0.7344\nEpoch 63/140\n7086/7086 [==============================] - 2s 219us/sample - loss: 1.5923 - mean_squared_error: 1.5923 - mean_absolute_error: 0.8199 - val_loss: 1.6066 - val_mean_squared_error: 1.6066 - val_mean_absolute_error: 0.7628\nEpoch 64/140\n7086/7086 [==============================] - 2s 216us/sample - loss: 1.6263 - mean_squared_error: 1.6263 - mean_absolute_error: 0.8305 - val_loss: 1.6073 - val_mean_squared_error: 1.6073 - val_mean_absolute_error: 0.7595\nEpoch 65/140\n7086/7086 [==============================] - 2s 218us/sample - loss: 1.6179 - mean_squared_error: 1.6179 - mean_absolute_error: 0.8253 - val_loss: 1.6136 - val_mean_squared_error: 1.6136 - val_mean_absolute_error: 0.7505\nEpoch 66/140\n7086/7086 [==============================] - 2s 217us/sample - loss: 1.6183 - mean_squared_error: 1.6183 - mean_absolute_error: 0.8264 - val_loss: 1.6340 - val_mean_squared_error: 1.6340 - val_mean_absolute_error: 0.7556\nEpoch 67/140\n7086/7086 [==============================] - 2s 214us/sample - loss: 1.6111 - mean_squared_error: 1.6111 - mean_absolute_error: 0.8191 - val_loss: 1.8565 - val_mean_squared_error: 1.8565 - val_mean_absolute_error: 1.0137\nEpoch 68/140\n7086/7086 [==============================] - 2s 212us/sample - loss: 1.6025 - mean_squared_error: 1.6025 - mean_absolute_error: 0.8235 - val_loss: 1.9307 - val_mean_squared_error: 1.9307 - val_mean_absolute_error: 1.0541\nEpoch 69/140\n7086/7086 [==============================] - 2s 215us/sample - loss: 1.5956 - mean_squared_error: 1.5956 - mean_absolute_error: 0.8219 - val_loss: 1.6074 - val_mean_squared_error: 1.6074 - val_mean_absolute_error: 0.7493\nEpoch 70/140\n7086/7086 [==============================] - 2s 217us/sample - loss: 1.6082 - mean_squared_error: 1.6082 - mean_absolute_error: 0.8231 - val_loss: 1.6115 - val_mean_squared_error: 1.6115 - val_mean_absolute_error: 0.7708\nEpoch 71/140\n7086/7086 [==============================] - 2s 215us/sample - loss: 1.6307 - mean_squared_error: 1.6307 - mean_absolute_error: 0.8321 - val_loss: 1.6070 - val_mean_squared_error: 1.6070 - val_mean_absolute_error: 0.7523\nEpoch 72/140\n7086/7086 [==============================] - 2s 213us/sample - loss: 1.5939 - mean_squared_error: 1.5939 - mean_absolute_error: 0.8192 - val_loss: 1.6066 - val_mean_squared_error: 1.6066 - val_mean_absolute_error: 0.7500\nEpoch 73/140\n7086/7086 [==============================] - 2s 213us/sample - loss: 1.5921 - mean_squared_error: 1.5921 - mean_absolute_error: 0.8147 - val_loss: 1.6098 - val_mean_squared_error: 1.6098 - val_mean_absolute_error: 0.7395\nEpoch 74/140\n7086/7086 [==============================] - 2s 214us/sample - loss: 1.5922 - mean_squared_error: 1.5922 - mean_absolute_error: 0.8149 - val_loss: 1.6105 - val_mean_squared_error: 1.6105 - val_mean_absolute_error: 0.7588\nEpoch 75/140\n7086/7086 [==============================] - 2s 213us/sample - loss: 1.6150 - mean_squared_error: 1.6150 - mean_absolute_error: 0.8245 - val_loss: 1.6808 - val_mean_squared_error: 1.6808 - val_mean_absolute_error: 0.7916\nEpoch 76/140\n7086/7086 [==============================] - 2s 214us/sample - loss: 1.5986 - mean_squared_error: 1.5986 - mean_absolute_error: 0.8182 - val_loss: 1.6004 - val_mean_squared_error: 1.6004 - val_mean_absolute_error: 0.7427\nEpoch 77/140\n7086/7086 [==============================] - 2s 253us/sample - loss: 1.5987 - mean_squared_error: 1.5987 - mean_absolute_error: 0.8180 - val_loss: 1.6257 - val_mean_squared_error: 1.6257 - val_mean_absolute_error: 0.7945\nEpoch 78/140\n7086/7086 [==============================] - 2s 268us/sample - loss: 1.6131 - mean_squared_error: 1.6131 - mean_absolute_error: 0.8195 - val_loss: 1.7763 - val_mean_squared_error: 1.7763 - val_mean_absolute_error: 0.9602\nEpoch 79/140\n7086/7086 [==============================] - 2s 242us/sample - loss: 1.6119 - mean_squared_error: 1.6119 - mean_absolute_error: 0.8230 - val_loss: 1.6028 - val_mean_squared_error: 1.6028 - val_mean_absolute_error: 0.7411\nEpoch 80/140\n7086/7086 [==============================] - 2s 235us/sample - loss: 1.5978 - mean_squared_error: 1.5978 - mean_absolute_error: 0.8199 - val_loss: 1.6220 - val_mean_squared_error: 1.6220 - val_mean_absolute_error: 0.7501\nEpoch 81/140\n7086/7086 [==============================] - 2s 235us/sample - loss: 1.5981 - mean_squared_error: 1.5981 - mean_absolute_error: 0.8172 - val_loss: 1.6362 - val_mean_squared_error: 1.6362 - val_mean_absolute_error: 0.7677\nEpoch 82/140\n7086/7086 [==============================] - 2s 229us/sample - loss: 1.5834 - mean_squared_error: 1.5834 - mean_absolute_error: 0.8115 - val_loss: 1.6127 - val_mean_squared_error: 1.6127 - val_mean_absolute_error: 0.7660\nEpoch 83/140\n7086/7086 [==============================] - 2s 233us/sample - loss: 1.6083 - mean_squared_error: 1.6083 - mean_absolute_error: 0.8272 - val_loss: 1.6462 - val_mean_squared_error: 1.6462 - val_mean_absolute_error: 0.7789\nEpoch 84/140\n7086/7086 [==============================] - 2s 226us/sample - loss: 1.6114 - mean_squared_error: 1.6114 - mean_absolute_error: 0.8203 - val_loss: 1.6535 - val_mean_squared_error: 1.6535 - val_mean_absolute_error: 0.7764\nEpoch 85/140\n7086/7086 [==============================] - 2s 226us/sample - loss: 1.6093 - mean_squared_error: 1.6093 - mean_absolute_error: 0.8156 - val_loss: 1.6461 - val_mean_squared_error: 1.6461 - val_mean_absolute_error: 0.8252\nEpoch 86/140\n7086/7086 [==============================] - 2s 229us/sample - loss: 1.5922 - mean_squared_error: 1.5922 - mean_absolute_error: 0.8148 - val_loss: 1.6151 - val_mean_squared_error: 1.6151 - val_mean_absolute_error: 0.7651\nEpoch 87/140\n7086/7086 [==============================] - 2s 265us/sample - loss: 1.5993 - mean_squared_error: 1.5993 - mean_absolute_error: 0.8176 - val_loss: 1.6076 - val_mean_squared_error: 1.6076 - val_mean_absolute_error: 0.7495\nEpoch 88/140\n7086/7086 [==============================] - 2s 260us/sample - loss: 1.5918 - mean_squared_error: 1.5918 - mean_absolute_error: 0.8175 - val_loss: 1.6177 - val_mean_squared_error: 1.6177 - val_mean_absolute_error: 0.7631\nEpoch 89/140\n7086/7086 [==============================] - 2s 247us/sample - loss: 1.5977 - mean_squared_error: 1.5977 - mean_absolute_error: 0.8157 - val_loss: 1.6221 - val_mean_squared_error: 1.6221 - val_mean_absolute_error: 0.7736\nEpoch 90/140\n7086/7086 [==============================] - 2s 213us/sample - loss: 1.6085 - mean_squared_error: 1.6085 - mean_absolute_error: 0.8180 - val_loss: 1.6295 - val_mean_squared_error: 1.6295 - val_mean_absolute_error: 0.7992\nEpoch 91/140\n7086/7086 [==============================] - 2s 218us/sample - loss: 1.6083 - mean_squared_error: 1.6083 - mean_absolute_error: 0.8211 - val_loss: 1.6764 - val_mean_squared_error: 1.6764 - val_mean_absolute_error: 0.7901\nEpoch 92/140\n7086/7086 [==============================] - 2s 214us/sample - loss: 1.6232 - mean_squared_error: 1.6232 - mean_absolute_error: 0.8206 - val_loss: 1.6782 - val_mean_squared_error: 1.6782 - val_mean_absolute_error: 0.8673\nEpoch 93/140\n7086/7086 [==============================] - 2s 215us/sample - loss: 1.5925 - mean_squared_error: 1.5925 - mean_absolute_error: 0.8146 - val_loss: 1.6019 - val_mean_squared_error: 1.6019 - val_mean_absolute_error: 0.7415\nEpoch 94/140\n7086/7086 [==============================] - 2s 212us/sample - loss: 1.5895 - mean_squared_error: 1.5895 - mean_absolute_error: 0.8135 - val_loss: 1.6460 - val_mean_squared_error: 1.6460 - val_mean_absolute_error: 0.7667\nEpoch 95/140\n7086/7086 [==============================] - 1s 211us/sample - loss: 1.6182 - mean_squared_error: 1.6182 - mean_absolute_error: 0.8192 - val_loss: 1.6162 - val_mean_squared_error: 1.6162 - val_mean_absolute_error: 0.7811\nEpoch 96/140\n7086/7086 [==============================] - 2s 217us/sample - loss: 1.5937 - mean_squared_error: 1.5937 - mean_absolute_error: 0.8142 - val_loss: 1.6295 - val_mean_squared_error: 1.6295 - val_mean_absolute_error: 0.8112\nEpoch 97/140\n7086/7086 [==============================] - 2s 213us/sample - loss: 1.5791 - mean_squared_error: 1.5791 - mean_absolute_error: 0.8093 - val_loss: 1.6059 - val_mean_squared_error: 1.6059 - val_mean_absolute_error: 0.7463\nEpoch 98/140\n7086/7086 [==============================] - 2s 215us/sample - loss: 1.5993 - mean_squared_error: 1.5993 - mean_absolute_error: 0.8190 - val_loss: 1.6567 - val_mean_squared_error: 1.6567 - val_mean_absolute_error: 0.8435\nEpoch 99/140\n7086/7086 [==============================] - 2s 213us/sample - loss: 1.5783 - mean_squared_error: 1.5783 - mean_absolute_error: 0.8130 - val_loss: 1.6350 - val_mean_squared_error: 1.6350 - val_mean_absolute_error: 0.8054\nEpoch 100/140\n7086/7086 [==============================] - 2s 214us/sample - loss: 1.5814 - mean_squared_error: 1.5814 - mean_absolute_error: 0.8094 - val_loss: 1.6540 - val_mean_squared_error: 1.6540 - val_mean_absolute_error: 0.8378\nEpoch 101/140\n7086/7086 [==============================] - 2s 217us/sample - loss: 1.5961 - mean_squared_error: 1.5961 - mean_absolute_error: 0.8169 - val_loss: 1.6857 - val_mean_squared_error: 1.6857 - val_mean_absolute_error: 0.8750\nEpoch 102/140\n7086/7086 [==============================] - 2s 214us/sample - loss: 1.5837 - mean_squared_error: 1.5837 - mean_absolute_error: 0.8138 - val_loss: 1.6064 - val_mean_squared_error: 1.6064 - val_mean_absolute_error: 0.7494\nEpoch 103/140\n7086/7086 [==============================] - 1s 211us/sample - loss: 1.5898 - mean_squared_error: 1.5898 - mean_absolute_error: 0.8127 - val_loss: 1.6077 - val_mean_squared_error: 1.6077 - val_mean_absolute_error: 0.7515\nEpoch 104/140\n7086/7086 [==============================] - 2s 214us/sample - loss: 1.6103 - mean_squared_error: 1.6103 - mean_absolute_error: 0.8170 - val_loss: 1.6096 - val_mean_squared_error: 1.6096 - val_mean_absolute_error: 0.7651\nEpoch 105/140\n7086/7086 [==============================] - 2s 217us/sample - loss: 1.6081 - mean_squared_error: 1.6081 - mean_absolute_error: 0.8185 - val_loss: 1.6242 - val_mean_squared_error: 1.6242 - val_mean_absolute_error: 0.7979\nEpoch 106/140\n7086/7086 [==============================] - 2s 216us/sample - loss: 1.5994 - mean_squared_error: 1.5994 - mean_absolute_error: 0.8113 - val_loss: 1.6032 - val_mean_squared_error: 1.6032 - val_mean_absolute_error: 0.7431\nEpoch 107/140\n7086/7086 [==============================] - 2s 217us/sample - loss: 1.5829 - mean_squared_error: 1.5829 - mean_absolute_error: 0.8102 - val_loss: 1.6204 - val_mean_squared_error: 1.6204 - val_mean_absolute_error: 0.7793\nEpoch 108/140\n7086/7086 [==============================] - 1s 211us/sample - loss: 1.5935 - mean_squared_error: 1.5935 - mean_absolute_error: 0.8134 - val_loss: 1.7083 - val_mean_squared_error: 1.7083 - val_mean_absolute_error: 0.9054\nEpoch 109/140\n7086/7086 [==============================] - 2s 216us/sample - loss: 1.5981 - mean_squared_error: 1.5981 - mean_absolute_error: 0.8161 - val_loss: 1.6097 - val_mean_squared_error: 1.6097 - val_mean_absolute_error: 0.7409\nEpoch 110/140\n7086/7086 [==============================] - 2s 214us/sample - loss: 1.5942 - mean_squared_error: 1.5942 - mean_absolute_error: 0.8132 - val_loss: 1.6072 - val_mean_squared_error: 1.6072 - val_mean_absolute_error: 0.7517\nEpoch 111/140\n7086/7086 [==============================] - 2s 214us/sample - loss: 1.5901 - mean_squared_error: 1.5901 - mean_absolute_error: 0.8121 - val_loss: 1.6394 - val_mean_squared_error: 1.6394 - val_mean_absolute_error: 0.8233\nEpoch 112/140\n7086/7086 [==============================] - 2s 213us/sample - loss: 1.5859 - mean_squared_error: 1.5859 - mean_absolute_error: 0.8076 - val_loss: 1.6315 - val_mean_squared_error: 1.6315 - val_mean_absolute_error: 0.8103\nEpoch 113/140\n7086/7086 [==============================] - 2s 212us/sample - loss: 1.5757 - mean_squared_error: 1.5757 - mean_absolute_error: 0.8085 - val_loss: 1.6076 - val_mean_squared_error: 1.6076 - val_mean_absolute_error: 0.7433\nEpoch 114/140\n7086/7086 [==============================] - 2s 212us/sample - loss: 1.6090 - mean_squared_error: 1.6090 - mean_absolute_error: 0.8106 - val_loss: 1.6242 - val_mean_squared_error: 1.6242 - val_mean_absolute_error: 0.8044\nEpoch 115/140\n7086/7086 [==============================] - 2s 212us/sample - loss: 1.5812 - mean_squared_error: 1.5812 - mean_absolute_error: 0.8045 - val_loss: 1.6095 - val_mean_squared_error: 1.6095 - val_mean_absolute_error: 0.7573\nEpoch 116/140\n7086/7086 [==============================] - 2s 215us/sample - loss: 1.5812 - mean_squared_error: 1.5812 - mean_absolute_error: 0.8114 - val_loss: 1.6765 - val_mean_squared_error: 1.6765 - val_mean_absolute_error: 0.8736\nEpoch 117/140\n7086/7086 [==============================] - 2s 274us/sample - loss: 1.5808 - mean_squared_error: 1.5808 - mean_absolute_error: 0.8113 - val_loss: 1.7066 - val_mean_squared_error: 1.7066 - val_mean_absolute_error: 0.8944\nEpoch 118/140\n7086/7086 [==============================] - 2s 272us/sample - loss: 1.5961 - mean_squared_error: 1.5961 - mean_absolute_error: 0.8128 - val_loss: 1.6245 - val_mean_squared_error: 1.6245 - val_mean_absolute_error: 0.7872\nEpoch 119/140\n7086/7086 [==============================] - 2s 251us/sample - loss: 1.6016 - mean_squared_error: 1.6016 - mean_absolute_error: 0.8120 - val_loss: 1.6379 - val_mean_squared_error: 1.6379 - val_mean_absolute_error: 0.8146\nEpoch 120/140\n7086/7086 [==============================] - 2s 227us/sample - loss: 1.5858 - mean_squared_error: 1.5858 - mean_absolute_error: 0.8101 - val_loss: 1.6117 - val_mean_squared_error: 1.6117 - val_mean_absolute_error: 0.7579\nEpoch 121/140\n7086/7086 [==============================] - 2s 226us/sample - loss: 1.5710 - mean_squared_error: 1.5710 - mean_absolute_error: 0.8023 - val_loss: 1.6209 - val_mean_squared_error: 1.6209 - val_mean_absolute_error: 0.7827\nEpoch 122/140\n7086/7086 [==============================] - 2s 230us/sample - loss: 1.5988 - mean_squared_error: 1.5988 - mean_absolute_error: 0.8116 - val_loss: 1.6438 - val_mean_squared_error: 1.6438 - val_mean_absolute_error: 0.8322\nEpoch 123/140\n7086/7086 [==============================] - 2s 227us/sample - loss: 1.5931 - mean_squared_error: 1.5931 - mean_absolute_error: 0.8092 - val_loss: 1.6376 - val_mean_squared_error: 1.6376 - val_mean_absolute_error: 0.8200\nEpoch 124/140\n7086/7086 [==============================] - 2s 240us/sample - loss: 1.5915 - mean_squared_error: 1.5915 - mean_absolute_error: 0.8125 - val_loss: 1.6048 - val_mean_squared_error: 1.6048 - val_mean_absolute_error: 0.7364\nEpoch 125/140\n7086/7086 [==============================] - 2s 230us/sample - loss: 1.5815 - mean_squared_error: 1.5815 - mean_absolute_error: 0.8094 - val_loss: 1.6080 - val_mean_squared_error: 1.6080 - val_mean_absolute_error: 0.7453\nEpoch 126/140\n7086/7086 [==============================] - 2s 228us/sample - loss: 1.5746 - mean_squared_error: 1.5746 - mean_absolute_error: 0.8048 - val_loss: 1.6054 - val_mean_squared_error: 1.6054 - val_mean_absolute_error: 0.7522\nEpoch 127/140\n7086/7086 [==============================] - 2s 257us/sample - loss: 1.5864 - mean_squared_error: 1.5864 - mean_absolute_error: 0.8088 - val_loss: 1.6382 - val_mean_squared_error: 1.6382 - val_mean_absolute_error: 0.8208\nEpoch 128/140\n7086/7086 [==============================] - 2s 261us/sample - loss: 1.5961 - mean_squared_error: 1.5961 - mean_absolute_error: 0.8134 - val_loss: 1.6088 - val_mean_squared_error: 1.6088 - val_mean_absolute_error: 0.7403\nEpoch 129/140\n7086/7086 [==============================] - 2s 260us/sample - loss: 1.5850 - mean_squared_error: 1.5850 - mean_absolute_error: 0.8069 - val_loss: 1.6057 - val_mean_squared_error: 1.6057 - val_mean_absolute_error: 0.7361\nEpoch 130/140\n7086/7086 [==============================] - 2s 226us/sample - loss: 1.5741 - mean_squared_error: 1.5741 - mean_absolute_error: 0.8047 - val_loss: 1.6089 - val_mean_squared_error: 1.6089 - val_mean_absolute_error: 0.7615\nEpoch 131/140\n7086/7086 [==============================] - 2s 218us/sample - loss: 1.5713 - mean_squared_error: 1.5713 - mean_absolute_error: 0.8027 - val_loss: 1.6456 - val_mean_squared_error: 1.6456 - val_mean_absolute_error: 0.8350\nEpoch 132/140\n7086/7086 [==============================] - 2s 214us/sample - loss: 1.5905 - mean_squared_error: 1.5905 - mean_absolute_error: 0.8131 - val_loss: 1.6113 - val_mean_squared_error: 1.6113 - val_mean_absolute_error: 0.7448\nEpoch 133/140\n7086/7086 [==============================] - 2s 217us/sample - loss: 1.5678 - mean_squared_error: 1.5678 - mean_absolute_error: 0.8023 - val_loss: 1.7776 - val_mean_squared_error: 1.7776 - val_mean_absolute_error: 0.9519\nEpoch 134/140\n7086/7086 [==============================] - 2s 216us/sample - loss: 1.5770 - mean_squared_error: 1.5770 - mean_absolute_error: 0.8072 - val_loss: 1.6160 - val_mean_squared_error: 1.6160 - val_mean_absolute_error: 0.7843\nEpoch 135/140\n7086/7086 [==============================] - 2s 212us/sample - loss: 1.5975 - mean_squared_error: 1.5975 - mean_absolute_error: 0.8099 - val_loss: 1.6562 - val_mean_squared_error: 1.6562 - val_mean_absolute_error: 0.8453\nEpoch 136/140\n7086/7086 [==============================] - 2s 214us/sample - loss: 1.5945 - mean_squared_error: 1.5945 - mean_absolute_error: 0.8118 - val_loss: 1.6111 - val_mean_squared_error: 1.6111 - val_mean_absolute_error: 0.7601\nEpoch 137/140\n7086/7086 [==============================] - 2s 213us/sample - loss: 1.5748 - mean_squared_error: 1.5748 - mean_absolute_error: 0.8096 - val_loss: 1.6041 - val_mean_squared_error: 1.6041 - val_mean_absolute_error: 0.7380\nEpoch 138/140\n7086/7086 [==============================] - 2s 216us/sample - loss: 1.5879 - mean_squared_error: 1.5879 - mean_absolute_error: 0.8081 - val_loss: 1.6189 - val_mean_squared_error: 1.6189 - val_mean_absolute_error: 0.7878\nEpoch 139/140\n7086/7086 [==============================] - 2s 216us/sample - loss: 1.5811 - mean_squared_error: 1.5811 - mean_absolute_error: 0.8056 - val_loss: 1.6263 - val_mean_squared_error: 1.6263 - val_mean_absolute_error: 0.8067\nEpoch 140/140\n7086/7086 [==============================] - 2s 215us/sample - loss: 1.5766 - mean_squared_error: 1.5766 - mean_absolute_error: 0.8012 - val_loss: 1.6305 - val_mean_squared_error: 1.6305 - val_mean_absolute_error: 0.8063\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f0fa4762ed0>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# model.fit(X_train,y_train,validation_split=0.2,epochs=100, batch_size=8,shuffle=True)\n",
    "model.fit(padded_sentences,label_norm,validation_split=0.2,epochs=140, batch_size=128,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('./final/embedding_model_bak.h5') \n",
    "# model = tf.keras.models.load_model('./final/embedding_model_bak.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_path = r'/data1/slm/datasets/JOB/synthetic/'\n",
    "# # test_path = r'/data/slm/datasets/JOB/job-light/'\n",
    "# # test_path = r'/data1/slm/datasets/JOB/cardinality/'\n",
    "# test_sentences,test_rows,test_pg = get_data_and_label(test_path)\n",
    "# test_data,test_label = prepare_data_and_label(test_sentences,test_rows)\n",
    "# print(np.shape(test_data),np.shape(test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # label_norm, min_val, max_val = normalize_labels(label)\n",
    "# max_len = 0\n",
    "# for test_sentence in test_sentences:\n",
    "#     if(len(test_sentence) > max_len):\n",
    "#         max_len = len(test_sentence)\n",
    "# print(max_len)\n",
    "# test_padded_sentences = pad_sequences(test_data, maxlen=max_len, padding='pre',dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.shape(test_padded_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = model.predict(test_padded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _pg = plt.scatter(test_label,test_pg,c='b')\n",
    "# my = plt.scatter(test_label,np.exp(pred),c='r')\n",
    "# plt.legend([_pg, my], ['pg', 'my'], loc='lower right', scatterpoints=1)\n",
    "# _max = max(test_label)\n",
    "# plt.plot([0,_max],[0,_max],c=\"y\")\n",
    "# plt.plot([0,_max],[0,2*_max],c=\"y\")\n",
    "# plt.plot([0,_max],[0,0.5*_max],c=\"y\")\n",
    "# plt.savefig(\"./results/test_embedding_result.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# result = np.exp(pred.flatten())/test_label\n",
    "# pg_result = np.array(test_pg)/np.array(test_label)\n",
    "# ax = plt.subplot(1, 2, 1)\n",
    "# ax.boxplot(np.log(np.array(result)),showfliers=False)\n",
    "# # ax.set_yticks(np.arange(0, 10))\n",
    "# # ax.set_yticklabels(math.e**np.arange(-10, 10))\n",
    "# ax.set_title('my q-error')\n",
    "# ax2 = plt.subplot(1,2,2)\n",
    "# ax2.boxplot(np.log(np.array(pg_result)),showfliers=False)\n",
    "# # ax2.set_yticklabels(math.e**np.arange(-10, 10))\n",
    "# ax2.set_title('pg q-error')\n",
    "# # plt.savefig(\"test_box-2.png\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# def print_qerror(preds_norm, labels_unnorm):\n",
    "#     qerror = []\n",
    "#     preds_unnorm = np.exp(preds_norm)-1\n",
    "# #     labels_unnorm = np.exp(labels_norm)-1\n",
    "#     for i in range(len(preds_unnorm)):\n",
    "#         if preds_unnorm[i] > float(labels_unnorm[i]):\n",
    "#             qerror.append(preds_unnorm[i] / float(labels_unnorm[i]))\n",
    "#         else:\n",
    "#             qerror.append(float(labels_unnorm[i]) / float(preds_unnorm[i]))\n",
    "\n",
    "#     print(\"Median: {}\".format(np.median(qerror)))\n",
    "#     print(\"90th percentile: {}\".format(np.percentile(qerror, 90)))\n",
    "#     print(\"95th percentile: {}\".format(np.percentile(qerror, 95)))\n",
    "#     print(\"99th percentile: {}\".format(np.percentile(qerror, 99)))\n",
    "#     print(\"Max: {}\".format(np.max(qerror)))\n",
    "#     print(\"Mean: {}\".format(np.mean(qerror)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_qerror(pred,test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bak better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.layers[6].output)\n",
    "# intermediate_output = intermediate_layer_model.predict(test_padded_sentences)\n",
    "\n",
    "intermediate_output = intermediate_layer_model.predict(padded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scan_label = []\n",
    "# scan_label.append(['table','detail'])\n",
    "# for sentence in sentences:\n",
    "#     tmp = []\n",
    "# #     print(sentence)\n",
    "#     table = sentence[0]\n",
    "#     tmp.append(table)\n",
    "#     if(len(sentence)>2):\n",
    "#         tmp.append(' '.join(str(each) for each in sentence[2:]))\n",
    "#     else:\n",
    "#         tmp.append(table)\n",
    "#     scan_label.append(tmp)\n",
    "# #     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savetxt(\"vectors.csv\", intermediate_output, delimiter=\"\\t\")\n",
    "# np.savetxt(\"labels.csv\",scan_label,fmt='%s',delimiter = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(8858, 64)\n"
    }
   ],
   "source": [
    "print(np.shape(intermediate_output))\n",
    "# print(np.shape(scan_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"model_parameter/featuer_cardinality.npy\",intermediate_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "8858"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "intermediate_output[:3]\n",
    "len(intermediate_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 592.875222,
   "position": {
    "height": "40px",
    "left": "901.667px",
    "right": "20px",
    "top": "87px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}