{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operators = ['Merge Join', 'Hash', 'Index Only Scan using title_pkey on title t', 'Sort','Seq Scan',\\\n",
    "              'Index Scan using title_pkey on title t', 'Materialize', 'Nested Loop', 'Hash Join']\n",
    "columns = ['ci.movie_id', 't.id', 'mi_idx.movie_id', 'mi.movie_id', 'mc.movie_id', 'mk.movie_id']\n",
    "# scan_features = np.load(\"./final/job-light_scan_features_64.npy\")\n",
    "# scan_features = np.load(\"./final/train_scan_features_64.npy\")\n",
    "scan_features = np.load(\"./final/test_scan_features_64.npy\")\n",
    "print(len(operators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10132, 64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(scan_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def extract_time(line):\n",
    "    data = line.replace(\"->\",\"\").lstrip().split(\"  \")[-1].split(\" \")\n",
    "    start_cost = data[0].split(\"..\")[0].replace(\"(cost=\",\"\")\n",
    "    end_cost = data[0].split(\"..\")[1]\n",
    "    rows = data[1].replace(\"rows=\",\"\")\n",
    "    width = data[2].replace(\"width=\",\"\").replace(\")\",\"\")\n",
    "    a_start_cost = data[4].split(\"..\")[0].replace(\"time=\",\"\")\n",
    "    a_end_cost = data[4].split(\"..\")[1]\n",
    "    a_rows = data[5].replace(\"rows=\",\"\") \n",
    "    return float(start_cost),float(end_cost),float(rows),float(width),float(a_start_cost),float(a_end_cost),float(a_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def extract_operator(line):\n",
    "    operator = line.replace(\"->\",\"\").lstrip().split(\"  \")[0]\n",
    "    if(operator.startswith(\"Seq Scan\")):\n",
    "        operator = \"Seq Scan\"\n",
    "    return operator,operator in operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": [
     0,
     23,
     31,
     35
    ]
   },
   "outputs": [],
   "source": [
    "def extract_attributes(operator,line,feature_vec,i=None):\n",
    "    operators = ['Merge Join', 'Hash', 'Index Only Scan using title_pkey on title t', 'Sort','Seq Scan',\\\n",
    "              'Index Scan using title_pkey on title t', 'Materialize', 'Nested Loop', 'Hash Join']\n",
    "    columns = ['ci.movie_id', 't.id', 'mi_idx.movie_id', 'mi.movie_id', 'mc.movie_id', 'mk.movie_id']\n",
    "    operators_count = len(operators) #9\n",
    "    if(operator in [\"Hash\",\"Materialize\",\"Nested Loop\"]): \n",
    "        pass\n",
    "    elif(operator==\"Merge Join\"):\n",
    "        if(\"Cond\" in line):\n",
    "            for column in columns:\n",
    "                if(column in line):\n",
    "                    feature_vec[columns.index(column)+operators_count] = 1.0\n",
    "    elif(operator==\"Index Only Scan using title_pkey on title t\"):\n",
    "#         feature_vec[15:56] = scan_features[i]\n",
    "        if(\"Cond\" in line):\n",
    "            feature_vec[columns.index(\"t.id\")+operators_count] = 1.0\n",
    "            for column in columns:\n",
    "                if(column in line):\n",
    "                    feature_vec[columns.index(column)+operators_count] = 1.0\n",
    "    elif(operator==\"Sort\"):\n",
    "        for column in columns:\n",
    "            if(column in line):\n",
    "                feature_vec[columns.index(column)+operators_count] = 1.0          \n",
    "    elif(operator=='Index Scan using title_pkey on title t'):\n",
    "#         feature_vec[15:56] = scan_features[i]\n",
    "        if(\"Cond\" in line):\n",
    "            feature_vec[columns.index(\"t.id\")+operators_count] = 1.0\n",
    "            for column in columns:\n",
    "                if(column in line):\n",
    "                    feature_vec[columns.index(column)+operators_count] = 1.0\n",
    "    elif(operator=='Hash Join'):\n",
    "        if(\"Cond\" in line):\n",
    "            for column in columns:\n",
    "                if(column in line):\n",
    "                    feature_vec[columns.index(column)+operators_count] = 1.0\n",
    "    elif(operator=='Seq Scan'):\n",
    "#         feature_vec[15:56] = scan_features[i]    #41\n",
    "        feature_vec[15:79] = scan_features[i]   #64\n",
    "#         feature_vec[15:47] = scan_features[i]   #32\n",
    "#         feature_vec[15:31] = scan_features[i]\n",
    "\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"Tree node class\"\"\"\n",
    "class Node(object):\n",
    "    def __init__(self, data, parent=None):\n",
    "        self.data = data\n",
    "        self.children = []\n",
    "        self.parent = parent\n",
    "\n",
    "    def add_child(self, obj):\n",
    "        self.children.append(obj)\n",
    "        \n",
    "    def add_parent(self, obj):\n",
    "        self.parent = obj\n",
    "        \n",
    "    def __str__(self, tabs=0):\n",
    "        tab_spaces = str.join(\"\", [\" \" for i in range(tabs)])\n",
    "        return tab_spaces + \"+-- Node: \"+ str.join(\"|\", self.data) + \"\\n\"\\\n",
    "                + str.join(\"\\n\", [child.__str__(tabs+2) for child in self.children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def parse_dep_tree_text(folder_name='/data1/slm/datasets/JOB/cardinality/'):\n",
    "    scan_cnt = 0\n",
    "    max_children = 0\n",
    "    plan_trees = []\n",
    "    feature_len = 9+6+7+64\n",
    "    for each_plan in sorted(os.listdir(folder_name)):\n",
    "#         print(each_plan)\n",
    "        with open(os.path.join(folder_name, each_plan), 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            feature_vec = [0.0]*feature_len\n",
    "            operator, in_operators = extract_operator(lines[0])\n",
    "            if not in_operators:\n",
    "                operator, in_operators = extract_operator(lines[1])\n",
    "                start_cost, end_cost, rows, width, a_start_cost, a_end_cost, a_rows = extract_time(\n",
    "                    lines[1])\n",
    "                j = 2\n",
    "            else:\n",
    "                start_cost, end_cost, rows, width, a_start_cost, a_end_cost, a_rows = extract_time(\n",
    "                    lines[0])\n",
    "                j = 1\n",
    "            feature_vec[feature_len-7:feature_len] = [start_cost,\n",
    "                                                      end_cost, rows, width, a_start_cost, a_end_cost, a_rows]\n",
    "            feature_vec[operators.index(operator)] = 1.0\n",
    "            if(operator == \"Seq Scan\"):\n",
    "                extract_attributes(operator, lines[j], feature_vec, scan_cnt)\n",
    "                scan_cnt += 1\n",
    "                root_tokens = feature_vec\n",
    "                current_node = Node(root_tokens)\n",
    "                plan_trees.append(current_node)\n",
    "                continue\n",
    "            else:\n",
    "                while(\"actual\" not in lines[j] and \"Plan\" not in lines[j]):\n",
    "                    extract_attributes(operator, lines[j], feature_vec)\n",
    "                    j += 1\n",
    "            root_tokens = feature_vec  # 所有吗\n",
    "            current_node = Node(root_tokens)\n",
    "            plan_trees.append(current_node)\n",
    "\n",
    "            spaces = 0\n",
    "            node_stack = []\n",
    "            i = j\n",
    "            while not lines[i].startswith(\"Planning time\"):\n",
    "                line = lines[i]\n",
    "                i += 1\n",
    "                if line.startswith(\"Planning time\") or line.startswith(\"Execution time\"):\n",
    "                    break\n",
    "                elif line.strip() == \"\":\n",
    "                    break\n",
    "                elif (\"->\" not in line):\n",
    "                    continue\n",
    "                else:\n",
    "                    if line.index(\"->\") < spaces:\n",
    "                        while line.index(\"->\") < spaces:\n",
    "                            current_node, spaces = node_stack.pop()\n",
    "\n",
    "                    if line.index(\"->\") > spaces:\n",
    "                        line_copy = line\n",
    "                        feature_vec = [0.0]*feature_len\n",
    "                        start_cost, end_cost, rows, width, a_start_cost, a_end_cost, a_rows = extract_time(\n",
    "                            line_copy)\n",
    "                        feature_vec[feature_len-7:feature_len] = [start_cost,\n",
    "                                                                  end_cost, rows, width, a_start_cost, a_end_cost, a_rows]\n",
    "                        operator, in_operators = extract_operator(line_copy)\n",
    "                        feature_vec[operators.index(operator)] = 1.0\n",
    "                        if(operator == \"Seq Scan\"):\n",
    "                            extract_attributes(\n",
    "                                operator, line_copy, feature_vec, scan_cnt)\n",
    "                            scan_cnt += 1\n",
    "                        else:\n",
    "                            j = 0\n",
    "                            while(\"actual\" not in lines[i+j] and \"Plan\" not in lines[i+j]):\n",
    "                                extract_attributes(\n",
    "                                    operator, lines[i+j], feature_vec)\n",
    "                                j += 1\n",
    "                        tokens = feature_vec\n",
    "                        new_node = Node(tokens, parent=current_node)\n",
    "                        current_node.add_child(new_node)\n",
    "                        if len(current_node.children) > max_children:\n",
    "                            max_children = len(current_node.children)\n",
    "                        node_stack.append((current_node, spaces))\n",
    "                        current_node = new_node\n",
    "                        spaces = line.index(\"->\")\n",
    "                    elif line.index(\"->\") == spaces:\n",
    "                        line_copy = line\n",
    "                        feature_vec = [0.0]*feature_len\n",
    "                        start_cost, end_cost, rows, width, a_start_cost, a_end_cost, a_rows = extract_time(\n",
    "                            line_copy)\n",
    "                        feature_vec[feature_len-7:feature_len] = [start_cost,\n",
    "                                                                  end_cost, rows, width, a_start_cost, a_end_cost, a_rows]\n",
    "                        operator, in_operators = extract_operator(line_copy)\n",
    "                        feature_vec[operators.index(operator)] = 1.0\n",
    "                        if(operator == \"Seq Scan\"):\n",
    "                            extract_attributes(\n",
    "                                operator, line_copy, feature_vec, scan_cnt)\n",
    "                            scan_cnt += 1\n",
    "                        else:\n",
    "                            j = 0\n",
    "                            while(\"actual\" not in lines[i+j] and \"Plan\" not in lines[i+j]):\n",
    "                                extract_attributes(\n",
    "                                    operator, lines[i+j], feature_vec)\n",
    "                                j += 1\n",
    "                        tokens = feature_vec\n",
    "                        new_node = Node(tokens, parent=node_stack[-1][0])\n",
    "                        node_stack[-1][0].add_child(new_node)\n",
    "                        if len(node_stack[-1][0].children) > max_children:\n",
    "                            max_children = len(node_stack[-1][0].children)\n",
    "                        current_node = new_node\n",
    "                        spaces = line.index(\"->\")\n",
    "#         break\n",
    "    print(scan_cnt)\n",
    "    return plan_trees, max_children  # a list of the roots nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0,
     11,
     16,
     44,
     46
    ]
   },
   "outputs": [],
   "source": [
    "def parse_dep_tree_text_lb_ub(folder_name='/data1/slm/datasets/JOB/cardinality/'):\n",
    "    scan_cnt = 0\n",
    "    max_children = 0\n",
    "    plan_trees = []\n",
    "    feature_len = 9+6+7+32\n",
    "    for each_plan in sorted(os.listdir(folder_name)):\n",
    "#         print(each_plan)\n",
    "        with open(os.path.join(folder_name, each_plan), 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            feature_vec = [0.0]*feature_len\n",
    "            operator, in_operators = extract_operator(lines[0])\n",
    "            if not in_operators:\n",
    "                operator, in_operators = extract_operator(lines[1])\n",
    "                start_cost, end_cost, rows, width, a_start_cost, a_end_cost, a_rows = extract_time(\n",
    "                    lines[1])\n",
    "                j = 2\n",
    "            else:\n",
    "                start_cost, end_cost, rows, width, a_start_cost, a_end_cost, a_rows = extract_time(\n",
    "                    lines[0])\n",
    "                j = 1\n",
    "            feature_vec[feature_len-7:feature_len] = [start_cost,\n",
    "                                                      end_cost, rows, width, a_start_cost, a_end_cost, a_rows]\n",
    "            feature_vec[operators.index(operator)] = 1.0\n",
    "            if(operator == \"Seq Scan\"):\n",
    "                extract_attributes(operator, lines[j], feature_vec, scan_cnt)\n",
    "                scan_cnt += 1\n",
    "                root_tokens = feature_vec\n",
    "                current_node = Node(root_tokens)\n",
    "                plan_trees.append(current_node)\n",
    "                continue\n",
    "            else:\n",
    "                while(\"actual\" not in lines[j] and \"Plan\" not in lines[j]):\n",
    "                    extract_attributes(operator, lines[j], feature_vec)\n",
    "                    j += 1\n",
    "            root_tokens = feature_vec  # 所有吗\n",
    "            current_node = Node(root_tokens)\n",
    "            plan_trees.append(current_node)\n",
    "\n",
    "            spaces = 0\n",
    "            node_stack = []\n",
    "            i = j\n",
    "            while not lines[i].startswith(\"Planning time\"):\n",
    "                line = lines[i]\n",
    "                i += 1\n",
    "                if line.startswith(\"Planning time\") or line.startswith(\"Execution time\"):\n",
    "                    break\n",
    "                elif line.strip() == \"\":\n",
    "                    break\n",
    "                elif (\"->\" not in line):\n",
    "                    continue\n",
    "                else:\n",
    "                    if line.index(\"->\") < spaces:\n",
    "                        while line.index(\"->\") < spaces:\n",
    "                            current_node, spaces = node_stack.pop()\n",
    "\n",
    "                    if line.index(\"->\") > spaces:\n",
    "                        line_copy = line\n",
    "                        feature_vec = [0.0]*feature_len\n",
    "                        start_cost, end_cost, rows, width, a_start_cost, a_end_cost, a_rows = extract_time(\n",
    "                            line_copy)\n",
    "                        feature_vec[feature_len-7:feature_len] = [start_cost,\n",
    "                                                                  end_cost, rows, width, a_start_cost, a_end_cost, a_rows]\n",
    "                        operator, in_operators = extract_operator(line_copy)\n",
    "                        feature_vec[operators.index(operator)] = 1.0\n",
    "                        if(operator == \"Seq Scan\" ):\n",
    "\n",
    "#                         if(operator == \"Seq Scan\" or operator == \"Index Only Scan using title_pkey on title t\" or operator=='Index Scan using title_pkey on title t'):\n",
    "                            extract_attributes(\n",
    "                                operator, line_copy, feature_vec, scan_cnt)\n",
    "                            scan_cnt += 1\n",
    "                        else:\n",
    "                            j = 0\n",
    "                            while(\"actual\" not in lines[i+j] and \"Plan\" not in lines[i+j]):\n",
    "                                extract_attributes(\n",
    "                                    operator, lines[i+j], feature_vec)\n",
    "                                j += 1\n",
    "                        tokens = feature_vec\n",
    "                        new_node = Node(tokens, parent=current_node)\n",
    "                        current_node.add_child(new_node)\n",
    "                        if len(current_node.children) > max_children:\n",
    "                            max_children = len(current_node.children)\n",
    "                        node_stack.append((current_node, spaces))\n",
    "                        current_node = new_node\n",
    "                        spaces = line.index(\"->\")\n",
    "                    elif line.index(\"->\") == spaces:\n",
    "                        line_copy = line\n",
    "                        feature_vec = [0.0]*feature_len\n",
    "                        start_cost, end_cost, rows, width, a_start_cost, a_end_cost, a_rows = extract_time(\n",
    "                            line_copy)\n",
    "                        feature_vec[feature_len-7:feature_len] = [start_cost,\n",
    "                                                                  end_cost, rows, width, a_start_cost, a_end_cost, a_rows]\n",
    "                        operator, in_operators = extract_operator(line_copy)\n",
    "                        feature_vec[operators.index(operator)] = 1.0\n",
    "                        if(operator == \"Seq Scan\" ):\n",
    "#                         if(operator == \"Seq Scan\" or operator == \"Index Only Scan using title_pkey on title t\" or operator=='Index Scan using title_pkey on title t'):\n",
    "                            extract_attributes(\n",
    "                                operator, line_copy, feature_vec, scan_cnt)\n",
    "                            scan_cnt += 1\n",
    "                        else:\n",
    "                            j = 0\n",
    "                            while(\"actual\" not in lines[i+j] and \"Plan\" not in lines[i+j]):\n",
    "                                extract_attributes(\n",
    "                                    operator, lines[i+j], feature_vec)\n",
    "                                j += 1\n",
    "                        tokens = feature_vec\n",
    "                        new_node = Node(tokens, parent=node_stack[-1][0])\n",
    "                        node_stack[-1][0].add_child(new_node)\n",
    "                        if len(node_stack[-1][0].children) > max_children:\n",
    "                            max_children = len(node_stack[-1][0].children)\n",
    "                        current_node = new_node\n",
    "                        spaces = line.index(\"->\")\n",
    "#         break\n",
    "    print(scan_cnt)\n",
    "    return plan_trees, max_children  # a list of the roots nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10132\n"
     ]
    }
   ],
   "source": [
    "# folder_name='/data1/slm/datasets/JOB/job-light/'\n",
    "folder_name='/data1/slm/datasets/JOB/synthetic/'\n",
    "# folder_name = '/data1/slm/datasets/JOB/cardinality/'\n",
    "trees,max_children = parse_dep_tree_text(folder_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def p2t(node):\n",
    "#         return float(start_cost),float(end_cost),float(rows),float(width),\n",
    "#         float(a_start_cost),float(a_end_cost),float(a_rows)\n",
    "    tree = {}\n",
    "    tmp = node.data\n",
    "    operators_count = 9\n",
    "    columns_count = 6\n",
    "    scan_features = 64\n",
    "    assert len(tmp) == operators_count + columns_count + 7 +scan_features \n",
    "    tree['features']= tmp[:operators_count + columns_count+scan_features]\n",
    "#     tree['features'].append(tmp[-5])  #with card as feature\n",
    "    tree['features'].append(tmp[-1])  #with Actual card as feature\n",
    "    #cardinality\n",
    "#     tree['labels'] = np.log(node.data[-1]+1) #cardinality\n",
    "#     tree['pg'] = np.log(node.data[-5])\n",
    "    #cost\n",
    "    tree['labels'] = np.log(node.data[-2]) #cost\n",
    "    tree['pg'] = np.log(node.data[-6])\n",
    "    tree['children'] = []\n",
    "    for children in node.children:\n",
    "        tree['children'].append(p2t(children))\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trees[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "all_trees = []\n",
    "for tree in trees:\n",
    "    all_trees.append(p2t(tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./final/test_cost_with_actual_card.pkl\",\"wb\") as f:\n",
    "    pickle.dump(all_trees,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.7017313,\n",
       "  1.0811665,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.14884652,\n",
       "  0.0,\n",
       "  0.6678157,\n",
       "  0.0,\n",
       "  0.44720152,\n",
       "  0.0,\n",
       "  1.5817659,\n",
       "  0.0,\n",
       "  0.788197,\n",
       "  0.2258005,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.30671957,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.7339276,\n",
       "  1.0239671,\n",
       "  0.87975585,\n",
       "  0.0,\n",
       "  0.7887193,\n",
       "  0.54926336,\n",
       "  0.0,\n",
       "  1.3286399,\n",
       "  0.0,\n",
       "  0.80977064,\n",
       "  0.45176077,\n",
       "  0.53813493,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.4868608,\n",
       "  0.99214697,\n",
       "  0.0,\n",
       "  0.6548313,\n",
       "  0.38311723,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.033585,\n",
       "  0.6540109,\n",
       "  0.62843794,\n",
       "  0.98227745,\n",
       "  0.0,\n",
       "  0.7143151,\n",
       "  0.664194,\n",
       "  0.50650674,\n",
       "  0.0,\n",
       "  0.71128887,\n",
       "  1.150971,\n",
       "  1.272905,\n",
       "  1.3934381,\n",
       "  1.5857081,\n",
       "  0.21341448,\n",
       "  0.0,\n",
       "  0.5985254],\n",
       " 'labels': 6.732210706467206,\n",
       " 'pg': 6.214608098422191,\n",
       " 'children': []}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_trees[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}